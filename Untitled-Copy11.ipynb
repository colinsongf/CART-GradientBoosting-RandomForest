{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, mean_squared_error, f1_score\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(s1, s2):\n",
    "    s = set(s2)\n",
    "    return filter(lambda x: x in s, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, depth, max_depth, impurity, is_leaf=False):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity = impurity\n",
    "        \n",
    "    def stopping_criteria(self, X, y):\n",
    "        if self.impurity == 'gini':\n",
    "            return self.depth >= self.max_depth or np.unique(y).shape[0] == 1\n",
    "        else:\n",
    "            return self.depth >= self.max_depth\n",
    "        \n",
    "    def get_answer(self, y):\n",
    "        if self.impurity == 'gini':\n",
    "            return Counter(y).most_common()[0][0]\n",
    "        else:                \n",
    "            return np.mean(y)\n",
    "        \n",
    "    def get_predicate(self, X, y, table, indices):\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_impurity = None\n",
    "        best_index = None\n",
    "    \n",
    "        for feature in np.arange(m):\n",
    "            if self.impurity == 'gini':\n",
    "                hist_left = Counter([])\n",
    "                hist_right = Counter(y[indices])\n",
    "                            \n",
    "                square_sum_left, square_sum_right = 0, np.sum(np.array(hist_right.values())**2)\n",
    "            else:\n",
    "                sum_left, sum_right = 0, np.sum(y[indices])                \n",
    "            \n",
    "            table_feature = intersection(table[feature], indices)\n",
    "            \n",
    "            n = len(table_feature)\n",
    "            \n",
    "            for ind, k in enumerate(table_feature[:-1]):\n",
    "\n",
    "                if self.impurity == 'gini':\n",
    "                    square_sum_left += 2 * hist_left[y[k]] + 1\n",
    "                    square_sum_right -= 2 * hist_right[y[k]] - 1\n",
    "\n",
    "                    hist_left[y[k]] += 1\n",
    "                    hist_right[y[k]] -= 1\n",
    "\n",
    "                    new_impurity = -float(square_sum_left) / (ind+1) - float(square_sum_right) / (n-ind-1)\n",
    "                else:\n",
    "                    sum_left += y[k]\n",
    "                    sum_right -= y[k]\n",
    "                    \n",
    "                    new_impurity = -sum_left**2 / float(ind+1) - sum_right**2 / float(n-ind-1)\n",
    "\n",
    "                if X[table_feature[ind+1], feature] > X[k, feature]:\n",
    "                    \n",
    "                    if best_feature is None or new_impurity < best_impurity:\n",
    "                        threshold = (X[k, feature] + X[table_feature[ind+1], feature]) / 2.\n",
    "\n",
    "                        best_feature = feature\n",
    "                        best_threshold = threshold\n",
    "                        best_impurity = new_impurity\n",
    "                        best_index = ind+1\n",
    "                \n",
    "        if best_feature is not None:\n",
    "            table_feature = intersection(table[best_feature], indices)\n",
    "\n",
    "            best_left  = table_feature[:best_index]\n",
    "            best_right = table_feature[best_index:]\n",
    "        else:\n",
    "            best_left  = None\n",
    "            best_right = None\n",
    "                \n",
    "        return best_feature, best_threshold, best_left, best_right\n",
    "        \n",
    "    def fit(self, X, y, table, indices):\n",
    "        \n",
    "        if self.stopping_criteria(X[indices], y[indices]):\n",
    "            self.is_leaf = True\n",
    "            self.answer = self.get_answer(y[indices])\n",
    "            return\n",
    "        \n",
    "        #t = time.time()\n",
    "        self.feature, self.threshold, left, right = self.get_predicate(X, y, table, indices)\n",
    "        #print \"Split: \", time.time() - t\n",
    "\n",
    "        if self.feature is None:\n",
    "            self.is_leaf = True\n",
    "            self.answer = self.get_answer(y[indices])            \n",
    "            return\n",
    "\n",
    "        self.left = Node(self.depth + 1, max_depth=self.max_depth, impurity=self.impurity)\n",
    "        self.left.fit(X, y, table, left)\n",
    "\n",
    "        self.right = Node(self.depth + 1, max_depth=self.max_depth, impurity=self.impurity)\n",
    "        self.right.fit(X, y, table, right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.is_leaf:\n",
    "            return self.answer\n",
    "        else:\n",
    "            if X[self.feature] <= self.threshold:\n",
    "                return self.left.predict(X)\n",
    "            else:\n",
    "                return self.right.predict(X)            \n",
    "        \n",
    "class CART:\n",
    "    def __init__(self, impurity='gini', max_depth=5):\n",
    "        if impurity not in ['gini', 'mse']:\n",
    "            raise ValueError(\"Only gini and mse criteria are supported\")\n",
    "        self.impurity = impurity\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        table = X.argsort(axis=0).T\n",
    "        indices = np.arange(X.shape[0])\n",
    "        \n",
    "        self.root = Node(0, max_depth=self.max_depth, impurity=self.impurity)                \n",
    "        self.root.fit(X, y, table, indices)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        answer = []\n",
    "        for x in X:\n",
    "            answer.append(self.root.predict(x))\n",
    "        return np.array(answer)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 4.7</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td> 6.4</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 4.5</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td> 6.9</td>\n",
       "      <td> 3.1</td>\n",
       "      <td> 4.9</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td> 5.5</td>\n",
       "      <td> 2.3</td>\n",
       "      <td> 4.0</td>\n",
       "      <td> 1.3</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td> 6.5</td>\n",
       "      <td> 2.8</td>\n",
       "      <td> 4.6</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width            class\n",
       "50           7.0          3.2           4.7          1.4  Iris-versicolor\n",
       "51           6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "52           6.9          3.1           4.9          1.5  Iris-versicolor\n",
       "53           5.5          2.3           4.0          1.3  Iris-versicolor\n",
       "54           6.5          2.8           4.6          1.5  Iris-versicolor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.data', delimiter=',')[50:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 0\n",
    "}\n",
    "\n",
    "df[\"num_class\"] = df[\"class\"].apply(lambda s: classes[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>   6.262000</td>\n",
       "      <td>   2.872000</td>\n",
       "      <td>   4.906000</td>\n",
       "      <td>   1.676000</td>\n",
       "      <td>   0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>   0.662834</td>\n",
       "      <td>   0.332751</td>\n",
       "      <td>   0.825578</td>\n",
       "      <td>   0.424769</td>\n",
       "      <td>   0.502519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>   4.900000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>   5.800000</td>\n",
       "      <td>   2.700000</td>\n",
       "      <td>   4.375000</td>\n",
       "      <td>   1.300000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>   6.300000</td>\n",
       "      <td>   2.900000</td>\n",
       "      <td>   4.900000</td>\n",
       "      <td>   1.600000</td>\n",
       "      <td>   0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>   6.700000</td>\n",
       "      <td>   3.025000</td>\n",
       "      <td>   5.525000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>   7.900000</td>\n",
       "      <td>   3.800000</td>\n",
       "      <td>   6.900000</td>\n",
       "      <td>   2.500000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width   num_class\n",
       "count    100.000000   100.000000    100.000000   100.000000  100.000000\n",
       "mean       6.262000     2.872000      4.906000     1.676000    0.500000\n",
       "std        0.662834     0.332751      0.825578     0.424769    0.502519\n",
       "min        4.900000     2.000000      3.000000     1.000000    0.000000\n",
       "25%        5.800000     2.700000      4.375000     1.300000    0.000000\n",
       "50%        6.300000     2.900000      4.900000     1.600000    0.500000\n",
       "75%        6.700000     3.025000      5.525000     2.000000    1.000000\n",
       "max        7.900000     3.800000      6.900000     2.500000    1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(df, train_percent=0.8):\n",
    "    X = np.copy(df.values)\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    X, y = X[:, :-1], X[:, -1]\n",
    "    \n",
    "    train_size = int(X.shape[0] * train_percent)\n",
    "    \n",
    "    X_train, y_train = X[:train_size, :], y[:train_size]\n",
    "    X_test, y_test = X[train_size:, :], y[train_size:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60; Test size: 40;\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle(df.drop(\"class\", axis=1), train_percent=0.6)\n",
    "print \"Train size: {}; Test size: {};\".format(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CART instance at 0x7f651262b3f8>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "cart_clf = CART(max_depth=10, impurity='mse')\n",
    "cart_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = cart_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1\n"
     ]
    }
   ],
   "source": [
    "#print \"Log loss: {}\".format(log_loss(y_test, pred))\n",
    "#print \"Accuracy: {}\".format(cart_clf.score(X_test, y_test))\n",
    "print \"MSE: {}\".format(mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
    "tree = DecisionTreeRegressor(max_depth=10, random_state=1)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1\n"
     ]
    }
   ],
   "source": [
    "#print \"Log loss: {}\".format(log_loss(y_test, sigmoid(pr)))\n",
    "#print \"Log loss: {}\".format(log_loss(y_test, pr))\n",
    "#print \"Accuracy: {}\".format(tree.score(X_test, y_test))\n",
    "print \"MSE: {}\".format(mean_squared_error(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=10, poi=1.0, pof=1.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.poi = poi\n",
    "        self.pof = pof\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        print \"Fitting random forest with {} estimators\".format(self.n_estimators)\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.estimators_features = []\n",
    "        \n",
    "        self.oob_score = []\n",
    "           \n",
    "        #np.random.seed(1543*1543)\n",
    "        np.random.seed(1)\n",
    "    \n",
    "        i = 0\n",
    "        for _ in xrange(self.n_estimators):\n",
    "            \n",
    "            i += 1\n",
    "            print \"Fitting estimator number {}\".format(i)\n",
    "            \n",
    "            n, m = X.shape\n",
    "            items    = np.sort(np.random.choice(n, n * self.poi))\n",
    "            features = np.sort(np.random.choice(m, m * self.pof, replace=False))\n",
    "            \n",
    "            mask = np.ones((X.shape[0],), dtype=bool)\n",
    "            mask[items] = 0\n",
    "            \n",
    "            #estimator = CART(max_depth=self.max_depth)\n",
    "            estimator = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            estimator.fit(X[:, features][items, :], y[items])\n",
    "            \n",
    "            self.estimators.append(estimator)\n",
    "            self.estimators_features.append(features)\n",
    "                        \n",
    "            self.oob_score.append(estimator.score(X[:, features][mask, :], y[mask]))\n",
    "        #print \"OOB score: {}\".format(np.mean(self.oob_score))\n",
    "        print \"OOB score: {}\".format(np.mean(self.oob_score))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        \n",
    "        prob = [Counter([])] * X.shape[0]\n",
    "        \n",
    "        for e, f, s in zip(self.estimators, self.estimators_features, self.oob_score):\n",
    "            p = e.predict(X[:, f])\n",
    "            answer += p\n",
    "\n",
    "            for i, a in enumerate(p):\n",
    "                prob[i][a] += 1\n",
    "                \n",
    "        answer /= self.n_estimators\n",
    "        answer = np.sign(answer)\n",
    "        #answer[answer == -1] = 0\n",
    "                    \n",
    "        #pprint.pprint(map(lambda c: np.array(c.values()) / float(X.shape[0] * self.n_estimators), prob))\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)        \n",
    "        return np.mean(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest with 100 estimators\n",
      "Fitting estimator number 1\n",
      "Fitting estimator number 2\n",
      "Fitting estimator number 3\n",
      "Fitting estimator number 4\n",
      "Fitting estimator number 5\n",
      "Fitting estimator number 6\n",
      "Fitting estimator number 7\n",
      "Fitting estimator number 8\n",
      "Fitting estimator number 9\n",
      "Fitting estimator number 10\n",
      "Fitting estimator number 11\n",
      "Fitting estimator number 12\n",
      "Fitting estimator number 13\n",
      "Fitting estimator number 14\n",
      "Fitting estimator number 15\n",
      "Fitting estimator number 16\n",
      "Fitting estimator number 17\n",
      "Fitting estimator number 18\n",
      "Fitting estimator number 19\n",
      "Fitting estimator number 20\n",
      "Fitting estimator number 21\n",
      "Fitting estimator number 22\n",
      "Fitting estimator number 23\n",
      "Fitting estimator number 24\n",
      "Fitting estimator number 25\n",
      "Fitting estimator number 26\n",
      "Fitting estimator number 27\n",
      "Fitting estimator number 28\n",
      "Fitting estimator number 29\n",
      "Fitting estimator number 30\n",
      "Fitting estimator number 31\n",
      "Fitting estimator number 32\n",
      "Fitting estimator number 33\n",
      "Fitting estimator number 34\n",
      "Fitting estimator number 35\n",
      "Fitting estimator number 36\n",
      "Fitting estimator number 37\n",
      "Fitting estimator number 38\n",
      "Fitting estimator number 39\n",
      "Fitting estimator number 40\n",
      "Fitting estimator number 41\n",
      "Fitting estimator number 42\n",
      "Fitting estimator number 43\n",
      "Fitting estimator number 44\n",
      "Fitting estimator number 45\n",
      "Fitting estimator number 46\n",
      "Fitting estimator number 47\n",
      "Fitting estimator number 48\n",
      "Fitting estimator number 49\n",
      "Fitting estimator number 50\n",
      "Fitting estimator number 51\n",
      "Fitting estimator number 52\n",
      "Fitting estimator number 53\n",
      "Fitting estimator number 54\n",
      "Fitting estimator number 55\n",
      "Fitting estimator number 56\n",
      "Fitting estimator number 57\n",
      "Fitting estimator number 58\n",
      "Fitting estimator number 59\n",
      "Fitting estimator number 60\n",
      "Fitting estimator number 61\n",
      "Fitting estimator number 62\n",
      "Fitting estimator number 63\n",
      "Fitting estimator number 64\n",
      "Fitting estimator number 65\n",
      "Fitting estimator number 66\n",
      "Fitting estimator number 67\n",
      "Fitting estimator number 68\n",
      "Fitting estimator number 69\n",
      "Fitting estimator number 70\n",
      "Fitting estimator number 71\n",
      "Fitting estimator number 72\n",
      "Fitting estimator number 73\n",
      "Fitting estimator number 74\n",
      "Fitting estimator number 75\n",
      "Fitting estimator number 76\n",
      "Fitting estimator number 77\n",
      "Fitting estimator number 78\n",
      "Fitting estimator number 79\n",
      "Fitting estimator number 80\n",
      "Fitting estimator number 81\n",
      "Fitting estimator number 82\n",
      "Fitting estimator number 83\n",
      "Fitting estimator number 84\n",
      "Fitting estimator number 85\n",
      "Fitting estimator number 86\n",
      "Fitting estimator number 87\n",
      "Fitting estimator number 88\n",
      "Fitting estimator number 89\n",
      "Fitting estimator number 90\n",
      "Fitting estimator number 91\n",
      "Fitting estimator number 92\n",
      "Fitting estimator number 93\n",
      "Fitting estimator number 94\n",
      "Fitting estimator number 95\n",
      "Fitting estimator number 96\n",
      "Fitting estimator number 97\n",
      "Fitting estimator number 98\n",
      "Fitting estimator number 99\n",
      "Fitting estimator number 100\n",
      "OOB score: 0.91555869811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "forest_clf_1 = RandomForest(n_estimators=100, max_depth=10)\n",
    "forest_clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=1.0, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=10, max_features=1.0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarize(y):\n",
    "    return np.array([-1 if x < 0.0 else 1 for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, mu=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth        \n",
    "        self.mu = mu\n",
    "    \n",
    "    def loss(self, y_true, y_pred):\n",
    "        return log_loss((y_true+1) / 2., (y_pred + 1) / 2.)\n",
    "    \n",
    "    def get_learning_rate(self, X, y, estimator):\n",
    "        \n",
    "        old = np.array(self.predict(X))\n",
    "        new = np.array(estimator.predict(X))\n",
    "\n",
    "        best_b = self.mu\n",
    "        best_loss = float(\"+inf\")\n",
    "        \n",
    "        b = 0.1\n",
    "        while b <= 10.0:\n",
    "            p = old + b * self.mu * new\n",
    "            p = binarize(p)\n",
    "            \n",
    "            loss = self.loss(y, p)\n",
    "            \n",
    "            if loss <= best_loss:                \n",
    "                best_b = b\n",
    "                best_loss = loss\n",
    "                \n",
    "            b += 0.1\n",
    "        \n",
    "        b = 10.0\n",
    "        while b <= 100.0:\n",
    "            p = old + b * self.mu * new\n",
    "            p = binarize(p)\n",
    "            \n",
    "            loss = self.loss(y, p)\n",
    "            if loss <= best_loss:\n",
    "                \n",
    "                best_b = b\n",
    "                best_loss = loss\n",
    "                \n",
    "            b += 1.0\n",
    "        \n",
    "        return self.mu * best_b\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        print \"Fitting gradient boosting with {} estimators\".format(self.n_estimators)\n",
    "        \n",
    "        self.estimators = []\n",
    "        self.weigths = []\n",
    "        \n",
    "        #estimator = CART(max_depth=1, impurity='mse')\n",
    "        #estimator.fit(X, y)\n",
    "        \n",
    "        #sk_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "        sk_estimator = DecisionTreeRegressor(max_depth=1)\n",
    "        sk_estimator.fit(X, y)\n",
    "        #print \"SK LOG LOSS: \", log_loss(y, sk_estimator.predict(X))\n",
    "        \n",
    "        #h = estimator.predict(X)\n",
    "        \n",
    "        #print \"LOG LOSS: \", log_loss(y, estimator.predict(X))\n",
    "        \n",
    "        self.estimators.append(sk_estimator)\n",
    "        self.weigths.append(1.)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        \n",
    "        old_loss = 0\n",
    "        \n",
    "        depth = self.max_depth        \n",
    "        for i in xrange(self.n_estimators):\n",
    "                    \n",
    "            print \"Fitting estimator number {}\".format(i+1)\n",
    "            \n",
    "            h = self.predict(X)\n",
    "            \n",
    "            g = (y+1)/2. - sigmoid((h+1)/2.)\n",
    "             \n",
    "            loss = self.loss(y_true=y, y_pred=binarize(h))\n",
    "            print \"Score: \", np.mean(y == binarize(h))\n",
    "            #loss = self.loss(y, h)        \n",
    "            print \"Loss: {}\\ndiff: {}\".format(loss, loss - old_loss)                    \n",
    "                        \n",
    "            old_loss = loss            \n",
    "                    \n",
    "            #estimator = CART(max_depth=depth, impurity='mse')\n",
    "            #estimator.fit(X, g)\n",
    "            \n",
    "            sk_estimator = DecisionTreeRegressor(max_depth=depth)\n",
    "            sk_estimator.fit(X, g)\n",
    "            \n",
    "            self.estimators.append(sk_estimator)\n",
    "                        \n",
    "            b = self.get_learning_rate(X, y, sk_estimator)                \n",
    "            self.weigths.append(b)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        for b, a in zip(self.weigths, self.estimators):            \n",
    "            answer += b * a.predict(X)\n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean(np.sign(pred) == y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting gradient boosting with 100 estimators\n",
      "SK LOG LOSS:  1.72693881975\n",
      "LOG LOSS:  1.72693881975\n",
      "Fitting estimator number 1\n",
      "Score:  0.95\n",
      "Loss: 1.72693881975\n",
      "diff: 1.72693881975\n",
      "Loss2: 0.162541486696\n",
      "Fitting estimator number 2\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: -1.72693881975\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 3\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 4\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 5\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 6\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 7\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 8\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 9\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 10\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 11\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 12\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 13\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 14\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 15\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 16\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 17\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 18\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 19\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 20\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 21\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 22\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 23\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 24\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 25\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 26\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 27\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 28\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 29\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 30\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 31\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 32\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 33\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 34\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 35\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 36\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 37\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 38\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 39\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 40\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 41\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 42\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 43\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 44\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 45\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 46\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 47\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 48\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 49\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 50\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 51\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 52\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 53\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 54\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 55\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 56\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 57\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 58\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 59\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 60\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 61\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 62\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 63\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 64\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 65\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 66\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 67\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 68\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 69\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 70\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 71\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 72\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 73\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 74\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 75\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 76\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 77\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 78\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 79\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 80\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 81\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 82\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 83\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 84\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 85\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 86\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 87\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 88\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 89\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 90\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 91\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 92\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 93\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 94\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 95\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 96\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 97\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 98\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 99\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n",
      "Fitting estimator number 100\n",
      "Score:  1.0\n",
      "Loss: 9.99200722163e-16\n",
      "diff: 0.0\n",
      "Loss2: 9.99200722163e-16\n"
     ]
    }
   ],
   "source": [
    "grad_clf_1 = GradientBoosting(n_estimators=100, mu=0.1)\n",
    "grad_clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clf_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "grad = GradientBoostingClassifier(n_estimators=100, max_depth=5)\n",
    "#grad = GradientBoostingRegressor(n_estimators=100, max_depth=5)\n",
    "grad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.45395759923\n"
     ]
    }
   ],
   "source": [
    "print log_loss(y_test, grad.predict(X_test))\n",
    "#grad.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VotingClassifier:\n",
    "    def __init__(self, estimators, weigths):\n",
    "        self.estimators = estimators\n",
    "        self.weights = weigths\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        for weight, estimator in zip(self.weights, self.estimators):\n",
    "            p = estimator.predict(X)            \n",
    "            answer += weight * p\n",
    "        answer = np.sign(answer / sum(self.weights))        \n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest with 100 estimators\n",
      "Fitting estimator number 1\n",
      "Fitting estimator number 2\n",
      "Fitting estimator number 3\n",
      "Fitting estimator number 4\n",
      "Fitting estimator number 5\n",
      "Fitting estimator number 6\n",
      "Fitting estimator number 7\n",
      "Fitting estimator number 8\n",
      "Fitting estimator number 9\n",
      "Fitting estimator number 10\n",
      "Fitting estimator number 11\n",
      "Fitting estimator number 12\n",
      "Fitting estimator number 13\n",
      "Fitting estimator number 14\n",
      "Fitting estimator number 15\n",
      "Fitting estimator number 16\n",
      "Fitting estimator number 17\n",
      "Fitting estimator number 18\n",
      "Fitting estimator number 19\n",
      "Fitting estimator number 20\n",
      "Fitting estimator number 21\n",
      "Fitting estimator number 22\n",
      "Fitting estimator number 23\n",
      "Fitting estimator number 24\n",
      "Fitting estimator number 25\n",
      "Fitting estimator number 26\n",
      "Fitting estimator number 27\n",
      "Fitting estimator number 28\n",
      "Fitting estimator number 29\n",
      "Fitting estimator number 30\n",
      "Fitting estimator number 31\n",
      "Fitting estimator number 32\n",
      "Fitting estimator number 33\n",
      "Fitting estimator number 34\n",
      "Fitting estimator number 35\n",
      "Fitting estimator number 36\n",
      "Fitting estimator number 37\n",
      "Fitting estimator number 38\n",
      "Fitting estimator number 39\n",
      "Fitting estimator number 40\n",
      "Fitting estimator number 41\n",
      "Fitting estimator number 42\n",
      "Fitting estimator number 43\n",
      "Fitting estimator number 44\n",
      "Fitting estimator number 45\n",
      "Fitting estimator number 46\n",
      "Fitting estimator number 47\n",
      "Fitting estimator number 48\n",
      "Fitting estimator number 49\n",
      "Fitting estimator number 50\n",
      "Fitting estimator number 51\n",
      "Fitting estimator number 52\n",
      "Fitting estimator number 53\n",
      "Fitting estimator number 54\n",
      "Fitting estimator number 55\n",
      "Fitting estimator number 56\n",
      "Fitting estimator number 57\n",
      "Fitting estimator number 58\n",
      "Fitting estimator number 59\n",
      "Fitting estimator number 60\n",
      "Fitting estimator number 61\n",
      "Fitting estimator number 62\n",
      "Fitting estimator number 63\n",
      "Fitting estimator number 64\n",
      "Fitting estimator number 65\n",
      "Fitting estimator number 66\n",
      "Fitting estimator number 67\n",
      "Fitting estimator number 68\n",
      "Fitting estimator number 69\n",
      "Fitting estimator number 70\n",
      "Fitting estimator number 71\n",
      "Fitting estimator number 72\n",
      "Fitting estimator number 73\n",
      "Fitting estimator number 74\n",
      "Fitting estimator number 75\n",
      "Fitting estimator number 76\n",
      "Fitting estimator number 77\n",
      "Fitting estimator number 78\n",
      "Fitting estimator number 79\n",
      "Fitting estimator number 80\n",
      "Fitting estimator number 81\n",
      "Fitting estimator number 82\n",
      "Fitting estimator number 83\n",
      "Fitting estimator number 84\n",
      "Fitting estimator number 85\n",
      "Fitting estimator number 86\n",
      "Fitting estimator number 87\n",
      "Fitting estimator number 88\n",
      "Fitting estimator number 89\n",
      "Fitting estimator number 90\n",
      "Fitting estimator number 91\n",
      "Fitting estimator number 92\n",
      "Fitting estimator number 93\n",
      "Fitting estimator number 94\n",
      "Fitting estimator number 95\n",
      "Fitting estimator number 96\n",
      "Fitting estimator number 97\n",
      "Fitting estimator number 98\n",
      "Fitting estimator number 99\n",
      "Fitting estimator number 100\n",
      "OOB score: [0.90909090909090906, 0.84210526315789469, 0.95833333333333337, 0.90909090909090906, 0.89473684210526316, 0.80000000000000004, 0.86363636363636365, 0.875, 0.88, 0.95238095238095233, 0.95454545454545459, 0.88888888888888884, 0.84999999999999998, 0.92000000000000004, 0.73684210526315785, 0.83333333333333337, 0.86956521739130432, 0.90909090909090906, 0.875, 0.86363636363636365, 0.86956521739130432, 0.90909090909090906, 0.84210526315789469, 0.90909090909090906, 0.90909090909090906, 0.91666666666666663, 0.86956521739130432, 0.90000000000000002, 0.83999999999999997, 0.80000000000000004, 0.89473684210526316, 0.91666666666666663, 0.84999999999999998, 0.76190476190476186, 0.72727272727272729, 0.95454545454545459, 0.8571428571428571, 0.95454545454545459, 0.86363636363636365, 0.84210526315789469, 0.91666666666666663, 0.8571428571428571, 0.90909090909090906, 0.95652173913043481, 0.86363636363636365, 0.92000000000000004, 0.88888888888888884, 0.80952380952380953, 0.91304347826086951, 0.88, 0.84999999999999998, 0.90000000000000002, 0.76190476190476186, 0.92000000000000004, 0.8571428571428571, 0.91666666666666663, 0.90000000000000002, 0.96153846153846156, 0.875, 0.92000000000000004, 0.77777777777777779, 0.91304347826086951, 0.89473684210526316, 0.83333333333333337, 0.875, 0.81818181818181823, 0.90909090909090906, 0.875, 0.94999999999999996, 0.90476190476190477, 0.8571428571428571, 0.95833333333333337, 0.81818181818181823, 0.94999999999999996, 0.81818181818181823, 0.78260869565217395, 0.91304347826086951, 0.91304347826086951, 0.73684210526315785, 0.80952380952380953, 0.83333333333333337, 0.89473684210526316, 0.875, 0.88235294117647056, 0.79166666666666663, 0.875, 0.94999999999999996, 0.91666666666666663, 0.81818181818181823, 0.91666666666666663, 0.82608695652173914, 0.875, 0.90476190476190477, 0.83333333333333337, 0.88, 0.8571428571428571, 1.0, 0.90909090909090906, 0.78947368421052633, 0.92307692307692313]\n",
      "Fitting gradient boosting with 100 estimators\n",
      "Fitting estimator number 1\n",
      "Loss: 0.379928354185\n",
      "diff: 0.379928354185\n",
      "5\n",
      "Fitting estimator number 2\n",
      "Loss: 0.369716130296\n",
      "diff: -0.0102122238884\n",
      "5\n",
      "Fitting estimator number 3\n",
      "Loss: 0.35990249905\n",
      "diff: -0.00981363124672\n",
      "5\n",
      "Fitting estimator number 4\n",
      "Loss: 0.350472987201\n",
      "diff: -0.00942951184924\n",
      "5\n",
      "Fitting estimator number 5\n",
      "Loss: 0.341413358166\n",
      "diff: -0.00905962903406\n",
      "5\n",
      "Fitting estimator number 6\n",
      "Loss: 0.332709606333\n",
      "diff: -0.00870375183326\n",
      "5\n",
      "Fitting estimator number 7\n",
      "Loss: 0.324347960333\n",
      "diff: -0.00836164600006\n",
      "5\n",
      "Fitting estimator number 8\n",
      "Loss: 0.316314893398\n",
      "diff: -0.00803306693533\n",
      "5\n",
      "Fitting estimator number 9\n",
      "Loss: 0.308597138889\n",
      "diff: -0.00771775450867\n",
      "5\n",
      "Fitting estimator number 10\n",
      "Loss: 0.301181709207\n",
      "diff: -0.00741542968178\n",
      "5\n",
      "Fitting estimator number 11\n",
      "Loss: 0.294055916436\n",
      "diff: -0.00712579277144\n",
      "5\n",
      "Fitting estimator number 12\n",
      "Loss: 0.287207393297\n",
      "diff: -0.0068485231388\n",
      "5\n",
      "Fitting estimator number 13\n",
      "Loss: 0.280624113235\n",
      "diff: -0.00658328006253\n",
      "5\n",
      "Fitting estimator number 14\n",
      "Loss: 0.274294408692\n",
      "diff: -0.00632970454221\n",
      "5\n",
      "Fitting estimator number 15\n",
      "Loss: 0.268206986909\n",
      "diff: -0.00608742178375\n",
      "5\n",
      "Fitting estimator number 16\n",
      "Loss: 0.262350942772\n",
      "diff: -0.00585604413657\n",
      "5\n",
      "Fitting estimator number 17\n",
      "Loss: 0.256715768494\n",
      "diff: -0.0056351742785\n",
      "5\n",
      "Fitting estimator number 18\n",
      "Loss: 0.251291360017\n",
      "diff: -0.0054244084761\n",
      "5\n",
      "Fitting estimator number 19\n",
      "Loss: 0.246068020236\n",
      "diff: -0.00522333978115\n",
      "5\n",
      "Fitting estimator number 20\n",
      "Loss: 0.241036459179\n",
      "diff: -0.00503156105716\n",
      "5\n",
      "Fitting estimator number 21\n",
      "Loss: 0.236187791419\n",
      "diff: -0.00484866775975\n",
      "5\n",
      "Fitting estimator number 22\n",
      "Loss: 0.231513530998\n",
      "diff: -0.0046742604217\n",
      "5\n",
      "Fitting estimator number 23\n",
      "Loss: 0.227005584182\n",
      "diff: -0.00450794681602\n",
      "5\n",
      "Fitting estimator number 24\n",
      "Loss: 0.222656240393\n",
      "diff: -0.00434934378842\n",
      "5\n",
      "Fitting estimator number 25\n",
      "Loss: 0.218458161628\n",
      "diff: -0.00419807876497\n",
      "5\n",
      "Fitting estimator number 26\n",
      "Loss: 0.214404370677\n",
      "diff: -0.00405379095086\n",
      "5\n",
      "Fitting estimator number 27\n",
      "Loss: 0.210488238434\n",
      "diff: -0.00391613224306\n",
      "5\n",
      "Fitting estimator number 28\n",
      "Loss: 0.20670347055\n",
      "diff: -0.00378476788437\n",
      "5\n",
      "Fitting estimator number 29\n",
      "Loss: 0.203044093662\n",
      "diff: -0.00365937688818\n",
      "5\n",
      "Fitting estimator number 30\n",
      "Loss: 0.199504441398\n",
      "diff: -0.00353965226378\n",
      "5\n",
      "Fitting estimator number 31\n",
      "Loss: 0.196079140326\n",
      "diff: -0.00342530107159\n",
      "5\n",
      "Fitting estimator number 32\n",
      "Loss: 0.192763095991\n",
      "diff: -0.00331604433548\n",
      "5\n",
      "Fitting estimator number 33\n",
      "Loss: 0.189551479153\n",
      "diff: -0.00321161683798\n",
      "5\n",
      "Fitting estimator number 34\n",
      "Loss: 0.186439712332\n",
      "diff: -0.00311176682093\n",
      "5\n",
      "Fitting estimator number 35\n",
      "Loss: 0.18342345672\n",
      "diff: -0.00301625561218\n",
      "5\n",
      "Fitting estimator number 36\n",
      "Loss: 0.180498599524\n",
      "diff: -0.00292485719598\n",
      "5\n",
      "Fitting estimator number 37\n",
      "Loss: 0.177661241781\n",
      "diff: -0.0028373577424\n",
      "5\n",
      "Fitting estimator number 38\n",
      "Loss: 0.174907686673\n",
      "diff: -0.00275355510878\n",
      "5\n",
      "Fitting estimator number 39\n",
      "Loss: 0.172234428349\n",
      "diff: -0.00267325832416\n",
      "5\n",
      "Fitting estimator number 40\n",
      "Loss: 0.169638141283\n",
      "diff: -0.00259628706558\n",
      "5\n",
      "Fitting estimator number 41\n",
      "Loss: 0.167115670149\n",
      "diff: -0.00252247113379\n",
      "5\n",
      "Fitting estimator number 42\n",
      "Loss: 0.164664020215\n",
      "diff: -0.00245164993411\n",
      "5\n",
      "Fitting estimator number 43\n",
      "Loss: 0.162280348248\n",
      "diff: -0.00238367196714\n",
      "5\n",
      "Fitting estimator number 44\n",
      "Loss: 0.159961953915\n",
      "diff: -0.00231839433294\n",
      "5\n",
      "Fitting estimator number 45\n",
      "Loss: 0.157706271664\n",
      "diff: -0.00225568225127\n",
      "5\n",
      "Fitting estimator number 46\n",
      "Loss: 0.155510863064\n",
      "diff: -0.00219540859996\n",
      "5\n",
      "Fitting estimator number 47\n",
      "Loss: 0.153373409591\n",
      "diff: -0.00213745347251\n",
      "5\n",
      "Fitting estimator number 48\n",
      "Loss: 0.151291705835\n",
      "diff: -0.00208170375593\n",
      "5\n",
      "Fitting estimator number 49\n",
      "Loss: 0.149263653106\n",
      "diff: -0.00202805272908\n",
      "5\n",
      "Fitting estimator number 50\n",
      "Loss: 0.147287253425\n",
      "diff: -0.00197639968155\n",
      "5\n",
      "Fitting estimator number 51\n",
      "Loss: 0.145360603872\n",
      "diff: -0.00192664955302\n",
      "5\n",
      "Fitting estimator number 52\n",
      "Loss: 0.143481891279\n",
      "diff: -0.00187871259251\n",
      "5\n",
      "Fitting estimator number 53\n",
      "Loss: 0.141649387242\n",
      "diff: -0.00183250403713\n",
      "5\n",
      "Fitting estimator number 54\n",
      "Loss: 0.139861443432\n",
      "diff: -0.00178794380954\n",
      "5\n",
      "Fitting estimator number 55\n",
      "Loss: 0.138116487199\n",
      "diff: -0.00174495623346\n",
      "5\n",
      "Fitting estimator number 56\n",
      "Loss: 0.136413017433\n",
      "diff: -0.00170346976642\n",
      "5\n",
      "Fitting estimator number 57\n",
      "Loss: 0.134749600684\n",
      "diff: -0.00166341674892\n",
      "5\n",
      "Fitting estimator number 58\n",
      "Loss: 0.133124867515\n",
      "diff: -0.0016247331691\n",
      "5\n",
      "Fitting estimator number 59\n",
      "Loss: 0.131537509072\n",
      "diff: -0.00158735844223\n",
      "5\n",
      "Fitting estimator number 60\n",
      "Loss: 0.129986273868\n",
      "diff: -0.00155123520404\n",
      "5\n",
      "Fitting estimator number 61\n",
      "Loss: 0.128469964751\n",
      "diff: -0.00151630911719\n",
      "5\n",
      "Fitting estimator number 62\n",
      "Loss: 0.126987436061\n",
      "diff: -0.00148252869007\n",
      "5\n",
      "Fitting estimator number 63\n",
      "Loss: 0.125537590954\n",
      "diff: -0.00144984510714\n",
      "5\n",
      "Fitting estimator number 64\n",
      "Loss: 0.124119378884\n",
      "diff: -0.00141821207013\n",
      "5\n",
      "Fitting estimator number 65\n",
      "Loss: 0.122731793234\n",
      "diff: -0.00138758564945\n",
      "5\n",
      "Fitting estimator number 66\n",
      "Loss: 0.121373869089\n",
      "diff: -0.00135792414507\n",
      "5\n",
      "Fitting estimator number 67\n",
      "Loss: 0.120044681133\n",
      "diff: -0.00132918795632\n",
      "5\n",
      "Fitting estimator number 68\n",
      "Loss: 0.118743341673\n",
      "diff: -0.00130133945998\n",
      "5\n",
      "Fitting estimator number 69\n",
      "Loss: 0.117468998777\n",
      "diff: -0.00127434289622\n",
      "5\n",
      "Fitting estimator number 70\n",
      "Loss: 0.116220834515\n",
      "diff: -0.0012481642617\n",
      "5\n",
      "Fitting estimator number 71\n",
      "Loss: 0.114998063306\n",
      "diff: -0.00122277120954\n",
      "5\n",
      "Fitting estimator number 72\n",
      "Loss: 0.11379993035\n",
      "diff: -0.0011981329555\n",
      "5\n",
      "Fitting estimator number 73\n",
      "Loss: 0.11262571016\n",
      "diff: -0.00117422019023\n",
      "5\n",
      "Fitting estimator number 74\n",
      "Loss: 0.111474705163\n",
      "diff: -0.00115100499685\n",
      "5\n",
      "Fitting estimator number 75\n",
      "Loss: 0.110346244389\n",
      "diff: -0.00112846077378\n",
      "5\n",
      "Fitting estimator number 76\n",
      "Loss: 0.109239682227\n",
      "diff: -0.00110656216234\n",
      "5\n",
      "Fitting estimator number 77\n",
      "Loss: 0.108154397248\n",
      "diff: -0.00108528497882\n",
      "5\n",
      "Fitting estimator number 78\n",
      "Loss: 0.107089791097\n",
      "diff: -0.00106460615073\n",
      "5\n",
      "Fitting estimator number 79\n",
      "Loss: 0.10604528744\n",
      "diff: -0.00104450365692\n",
      "5\n",
      "Fitting estimator number 80\n",
      "Loss: 0.105020330969\n",
      "diff: -0.00102495647143\n",
      "5\n",
      "Fitting estimator number 81\n",
      "Loss: 0.104014386458\n",
      "diff: -0.00100594451062\n",
      "5\n",
      "Fitting estimator number 82\n",
      "Loss: 0.103026937875\n",
      "diff: -0.000987448583536\n",
      "5\n",
      "Fitting estimator number 83\n",
      "Loss: 0.102057487529\n",
      "diff: -0.000969450345271\n",
      "5\n",
      "Fitting estimator number 84\n",
      "Loss: 0.101105555276\n",
      "diff: -0.000951932253027\n",
      "5\n",
      "Fitting estimator number 85\n",
      "Loss: 0.100170677752\n",
      "diff: -0.000934877524822\n",
      "5\n",
      "Fitting estimator number 86\n",
      "Loss: 0.0992524076511\n",
      "diff: -0.000918270100587\n",
      "5\n",
      "Fitting estimator number 87\n",
      "Loss: 0.0983503130455\n",
      "diff: -0.000902094605548\n",
      "5\n",
      "Fitting estimator number 88\n",
      "Loss: 0.0974639767298\n",
      "diff: -0.000886336315718\n",
      "5\n",
      "Fitting estimator number 89\n",
      "Loss: 0.0965929956044\n",
      "diff: -0.000870981125372\n",
      "5\n",
      "Fitting estimator number 90\n",
      "Loss: 0.095736980088\n",
      "diff: -0.000856015516382\n",
      "5\n",
      "Fitting estimator number 91\n",
      "Loss: 0.0948955535587\n",
      "diff: -0.000841426529293\n",
      "5\n",
      "Fitting estimator number 92\n",
      "Loss: 0.0940683518227\n",
      "diff: -0.000827201736022\n",
      "5\n",
      "Fitting estimator number 93\n",
      "Loss: 0.0932550226086\n",
      "diff: -0.000813329214091\n",
      "5\n",
      "Fitting estimator number 94\n",
      "Loss: 0.0924552250863\n",
      "diff: -0.000799797522291\n",
      "5\n",
      "Fitting estimator number 95\n",
      "Loss: 0.0916686294086\n",
      "diff: -0.000786595677685\n",
      "5\n",
      "Fitting estimator number 96\n",
      "Loss: 0.0908949162748\n",
      "diff: -0.000773713133879\n",
      "5\n",
      "Fitting estimator number 97\n",
      "Loss: 0.0901337765143\n",
      "diff: -0.000761139760468\n",
      "5\n",
      "Fitting estimator number 98\n",
      "Loss: 0.0893849106907\n",
      "diff: -0.0007488658236\n",
      "5\n",
      "Fitting estimator number 99\n",
      "Loss: 0.0886480287231\n",
      "diff: -0.00073688196758\n",
      "5\n",
      "Fitting estimator number 100\n",
      "Loss: 0.0879228495257\n",
      "diff: -0.000725179197458\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "vote_clf = VotingClassifier([forest_clf, grad_clf], [1.0, 1.0])\n",
    "vote_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000000000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.349723</td>\n",
       "      <td> 0.658872</td>\n",
       "      <td> 0.341822</td>\n",
       "      <td> 0.369098</td>\n",
       "      <td> 0.448115</td>\n",
       "      <td> 0.327417</td>\n",
       "      <td> 0.517556</td>\n",
       "      <td> 0.393646</td>\n",
       "      <td> 0.430504</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.470654</td>\n",
       "      <td> 0.410545</td>\n",
       "      <td> 0.590262</td>\n",
       "      <td> 0.450158</td>\n",
       "      <td> 0.443301</td>\n",
       "      <td> 0.467284</td>\n",
       "      <td> 0.438850</td>\n",
       "      <td> 0.413235</td>\n",
       "      <td> 0.433625</td>\n",
       "      <td> 0.575691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.320356</td>\n",
       "      <td> 0.214419</td>\n",
       "      <td> 0.796892</td>\n",
       "      <td> 0.283771</td>\n",
       "      <td> 0.429499</td>\n",
       "      <td> 0.336705</td>\n",
       "      <td> 0.209530</td>\n",
       "      <td> 0.411694</td>\n",
       "      <td> 0.620735</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.470654</td>\n",
       "      <td> 0.410545</td>\n",
       "      <td> 0.454687</td>\n",
       "      <td> 0.450158</td>\n",
       "      <td> 0.443301</td>\n",
       "      <td> 0.467284</td>\n",
       "      <td> 0.438850</td>\n",
       "      <td> 0.413235</td>\n",
       "      <td> 0.433625</td>\n",
       "      <td> 0.354707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.575150</td>\n",
       "      <td> 0.658872</td>\n",
       "      <td> 0.341822</td>\n",
       "      <td> 0.541797</td>\n",
       "      <td> 0.430258</td>\n",
       "      <td> 0.575468</td>\n",
       "      <td> 0.509843</td>\n",
       "      <td> 0.518629</td>\n",
       "      <td> 0.383852</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.470654</td>\n",
       "      <td> 0.410545</td>\n",
       "      <td> 0.454687</td>\n",
       "      <td> 0.450158</td>\n",
       "      <td> 0.443301</td>\n",
       "      <td> 0.467284</td>\n",
       "      <td> 0.992203</td>\n",
       "      <td> 0.768557</td>\n",
       "      <td> 0.433625</td>\n",
       "      <td> 0.391791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.349723</td>\n",
       "      <td> 0.658872</td>\n",
       "      <td> 0.341822</td>\n",
       "      <td> 0.440102</td>\n",
       "      <td> 0.455950</td>\n",
       "      <td> 0.327417</td>\n",
       "      <td> 0.560001</td>\n",
       "      <td> 0.398133</td>\n",
       "      <td> 0.376336</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.470654</td>\n",
       "      <td> 0.410545</td>\n",
       "      <td> 0.607055</td>\n",
       "      <td> 0.450158</td>\n",
       "      <td> 0.443301</td>\n",
       "      <td> 0.467284</td>\n",
       "      <td> 0.438850</td>\n",
       "      <td> 0.413235</td>\n",
       "      <td> 0.433625</td>\n",
       "      <td> 0.550478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.320356</td>\n",
       "      <td> 0.658872</td>\n",
       "      <td> 0.341822</td>\n",
       "      <td> 0.385197</td>\n",
       "      <td> 0.437169</td>\n",
       "      <td> 0.709301</td>\n",
       "      <td> 0.419971</td>\n",
       "      <td> 0.288835</td>\n",
       "      <td> 0.382394</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.470654</td>\n",
       "      <td> 0.410545</td>\n",
       "      <td> 0.454687</td>\n",
       "      <td> 0.450158</td>\n",
       "      <td> 0.443301</td>\n",
       "      <td> 0.467284</td>\n",
       "      <td> 0.438850</td>\n",
       "      <td> 0.413235</td>\n",
       "      <td> 0.433625</td>\n",
       "      <td> 0.741449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0    1  0.349723  0.658872  0.341822  0.369098  0.448115  0.327417  0.517556   \n",
       "1    1  0.320356  0.214419  0.796892  0.283771  0.429499  0.336705  0.209530   \n",
       "2    1  0.575150  0.658872  0.341822  0.541797  0.430258  0.575468  0.509843   \n",
       "3    1  0.349723  0.658872  0.341822  0.440102  0.455950  0.327417  0.560001   \n",
       "4    1  0.320356  0.658872  0.341822  0.385197  0.437169  0.709301  0.419971   \n",
       "\n",
       "        8         9      ...          93        94        95        96   \\\n",
       "0  0.393646  0.430504    ...     0.470654  0.410545  0.590262  0.450158   \n",
       "1  0.411694  0.620735    ...     0.470654  0.410545  0.454687  0.450158   \n",
       "2  0.518629  0.383852    ...     0.470654  0.410545  0.454687  0.450158   \n",
       "3  0.398133  0.376336    ...     0.470654  0.410545  0.607055  0.450158   \n",
       "4  0.288835  0.382394    ...     0.470654  0.410545  0.454687  0.450158   \n",
       "\n",
       "        97        98        99        100       101       102  \n",
       "0  0.443301  0.467284  0.438850  0.413235  0.433625  0.575691  \n",
       "1  0.443301  0.467284  0.438850  0.413235  0.433625  0.354707  \n",
       "2  0.443301  0.467284  0.992203  0.768557  0.433625  0.391791  \n",
       "3  0.443301  0.467284  0.438850  0.413235  0.433625  0.550478  \n",
       "4  0.443301  0.467284  0.438850  0.413235  0.433625  0.741449  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train_df = pd.read_csv('spam.train.txt', header=None, delimiter=\" \")\n",
    "spam_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_X_train = np.copy(spam_train_df.values)\n",
    "#np.random.shuffle(spam_X_train)\n",
    "spam_X_train, spam_y_train = spam_X_train[:, 1:], spam_X_train[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.445622</td>\n",
       "      <td> 0.632602</td>\n",
       "      <td> 0.368683</td>\n",
       "      <td> 0.728974</td>\n",
       "      <td> 0.479510</td>\n",
       "      <td> 0.471833</td>\n",
       "      <td> 0.571882</td>\n",
       "      <td> 0.579280</td>\n",
       "      <td> 0.604702</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.462762</td>\n",
       "      <td> 0.448051</td>\n",
       "      <td> 0.446374</td>\n",
       "      <td> 0.424879</td>\n",
       "      <td> 0.472828</td>\n",
       "      <td> 0.450815</td>\n",
       "      <td> 0.427943</td>\n",
       "      <td> 0.416184</td>\n",
       "      <td> 0.446429</td>\n",
       "      <td> 0.667609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.296747</td>\n",
       "      <td> 0.632602</td>\n",
       "      <td> 0.368683</td>\n",
       "      <td> 0.330429</td>\n",
       "      <td> 0.374055</td>\n",
       "      <td> 0.451231</td>\n",
       "      <td> 0.249144</td>\n",
       "      <td> 0.431370</td>\n",
       "      <td> 0.344248</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.462762</td>\n",
       "      <td> 0.448051</td>\n",
       "      <td> 0.916790</td>\n",
       "      <td> 0.424879</td>\n",
       "      <td> 0.472828</td>\n",
       "      <td> 0.368804</td>\n",
       "      <td> 0.464272</td>\n",
       "      <td> 0.400264</td>\n",
       "      <td> 0.547989</td>\n",
       "      <td> 0.580435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.296747</td>\n",
       "      <td> 0.632602</td>\n",
       "      <td> 0.368683</td>\n",
       "      <td> 0.309466</td>\n",
       "      <td> 0.392561</td>\n",
       "      <td> 0.458103</td>\n",
       "      <td> 0.289492</td>\n",
       "      <td> 0.595944</td>\n",
       "      <td> 0.574234</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.462762</td>\n",
       "      <td> 0.448051</td>\n",
       "      <td> 0.798868</td>\n",
       "      <td> 0.424879</td>\n",
       "      <td> 0.472828</td>\n",
       "      <td> 0.368804</td>\n",
       "      <td> 0.472316</td>\n",
       "      <td> 0.415417</td>\n",
       "      <td> 0.446429</td>\n",
       "      <td> 0.781863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.296747</td>\n",
       "      <td> 0.184437</td>\n",
       "      <td> 0.831801</td>\n",
       "      <td> 0.239714</td>\n",
       "      <td> 0.494042</td>\n",
       "      <td> 0.716275</td>\n",
       "      <td> 0.295862</td>\n",
       "      <td> 0.349747</td>\n",
       "      <td> 0.434139</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.462762</td>\n",
       "      <td> 0.448051</td>\n",
       "      <td> 0.446374</td>\n",
       "      <td> 0.424879</td>\n",
       "      <td> 0.472828</td>\n",
       "      <td> 0.368804</td>\n",
       "      <td> 0.427943</td>\n",
       "      <td> 0.854188</td>\n",
       "      <td> 0.543903</td>\n",
       "      <td> 0.562639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.368046</td>\n",
       "      <td> 0.632602</td>\n",
       "      <td> 0.368683</td>\n",
       "      <td> 0.280957</td>\n",
       "      <td> 0.380190</td>\n",
       "      <td> 0.445567</td>\n",
       "      <td> 0.339384</td>\n",
       "      <td> 0.534049</td>\n",
       "      <td> 0.522703</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.462762</td>\n",
       "      <td> 0.448051</td>\n",
       "      <td> 0.446374</td>\n",
       "      <td> 0.533793</td>\n",
       "      <td> 0.472828</td>\n",
       "      <td> 0.812761</td>\n",
       "      <td> 0.473772</td>\n",
       "      <td> 0.400264</td>\n",
       "      <td> 0.446429</td>\n",
       "      <td> 0.659760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0    1  0.445622  0.632602  0.368683  0.728974  0.479510  0.471833  0.571882   \n",
       "1    1  0.296747  0.632602  0.368683  0.330429  0.374055  0.451231  0.249144   \n",
       "2    1  0.296747  0.632602  0.368683  0.309466  0.392561  0.458103  0.289492   \n",
       "3    1  0.296747  0.184437  0.831801  0.239714  0.494042  0.716275  0.295862   \n",
       "4    1  0.368046  0.632602  0.368683  0.280957  0.380190  0.445567  0.339384   \n",
       "\n",
       "        8         9      ...          93        94        95        96   \\\n",
       "0  0.579280  0.604702    ...     0.462762  0.448051  0.446374  0.424879   \n",
       "1  0.431370  0.344248    ...     0.462762  0.448051  0.916790  0.424879   \n",
       "2  0.595944  0.574234    ...     0.462762  0.448051  0.798868  0.424879   \n",
       "3  0.349747  0.434139    ...     0.462762  0.448051  0.446374  0.424879   \n",
       "4  0.534049  0.522703    ...     0.462762  0.448051  0.446374  0.533793   \n",
       "\n",
       "        97        98        99        100       101       102  \n",
       "0  0.472828  0.450815  0.427943  0.416184  0.446429  0.667609  \n",
       "1  0.472828  0.368804  0.464272  0.400264  0.547989  0.580435  \n",
       "2  0.472828  0.368804  0.472316  0.415417  0.446429  0.781863  \n",
       "3  0.472828  0.368804  0.427943  0.854188  0.543903  0.562639  \n",
       "4  0.472828  0.812761  0.473772  0.400264  0.446429  0.659760  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test_df = pd.read_csv('spam.test.txt', header=None, delimiter=\" \")\n",
    "spam_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_X_test = np.copy(spam_test_df.values)\n",
    "np.random.shuffle(spam_X_test)\n",
    "spam_X_test, spam_y_test = spam_X_test[:, 1:], spam_X_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "spam_y_train[spam_y_train == 0] = -1\n",
    "spam_y_test[spam_y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.857895783612\n",
      "precision =  0.781829481793\n",
      "recall =  0.855306334917\n",
      "f1 =  0.806920036154\n"
     ]
    }
   ],
   "source": [
    "cart_clf = CART(max_depth=5)\n",
    "cart_clf.fit(spam_X_train, spam_y_train)\n",
    "\n",
    "print \"score: \", cart_clf.score(spam_X_test, spam_y_test)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(spam_y_test, cart_clf.predict(spam_X_test))\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "print \"f1 = \", f.mean()\n",
    "\n",
    "#forest_clf = RandomForest(n_estimators=300, max_depth=5, poi=0.7, pof=0.3)\n",
    "#grad_clf = GradientBoosting(n_estimators=300)\n",
    "\n",
    "#vote_clf = VotingClassifier([forest_clf, grad_clf], [1.0, 1.0])\n",
    "#vote_clf.fit(spam_X_train, spam_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest with 300 estimators\n",
      "Fitting estimator number 1\n",
      "Fitting estimator number 2\n",
      "Fitting estimator number 3\n",
      "Fitting estimator number 4\n",
      "Fitting estimator number 5\n",
      "Fitting estimator number 6\n",
      "Fitting estimator number 7\n",
      "Fitting estimator number 8\n",
      "Fitting estimator number 9\n",
      "Fitting estimator number 10\n",
      "Fitting estimator number 11\n",
      "Fitting estimator number 12\n",
      "Fitting estimator number 13\n",
      "Fitting estimator number 14\n",
      "Fitting estimator number 15\n",
      "Fitting estimator number 16\n",
      "Fitting estimator number 17\n",
      "Fitting estimator number 18\n",
      "Fitting estimator number 19\n",
      "Fitting estimator number 20\n",
      "Fitting estimator number 21\n",
      "Fitting estimator number 22\n",
      "Fitting estimator number 23\n",
      "Fitting estimator number 24\n",
      "Fitting estimator number 25\n",
      "Fitting estimator number 26\n",
      "Fitting estimator number 27\n",
      "Fitting estimator number 28\n",
      "Fitting estimator number 29\n",
      "Fitting estimator number 30\n",
      "Fitting estimator number 31\n",
      "Fitting estimator number 32\n",
      "Fitting estimator number 33\n",
      "Fitting estimator number 34\n",
      "Fitting estimator number 35\n",
      "Fitting estimator number 36\n",
      "Fitting estimator number 37\n",
      "Fitting estimator number 38\n",
      "Fitting estimator number 39\n",
      "Fitting estimator number 40\n",
      "Fitting estimator number 41\n",
      "Fitting estimator number 42\n",
      "Fitting estimator number 43\n",
      "Fitting estimator number 44\n",
      "Fitting estimator number 45\n",
      "Fitting estimator number 46\n",
      "Fitting estimator number 47\n",
      "Fitting estimator number 48\n",
      "Fitting estimator number 49\n",
      "Fitting estimator number 50\n",
      "Fitting estimator number 51\n",
      "Fitting estimator number 52\n",
      "Fitting estimator number 53\n",
      "Fitting estimator number 54\n",
      "Fitting estimator number 55\n",
      "Fitting estimator number 56\n",
      "Fitting estimator number 57\n",
      "Fitting estimator number 58\n",
      "Fitting estimator number 59\n",
      "Fitting estimator number 60\n",
      "Fitting estimator number 61\n",
      "Fitting estimator number 62\n",
      "Fitting estimator number 63\n",
      "Fitting estimator number 64\n",
      "Fitting estimator number 65\n",
      "Fitting estimator number 66\n",
      "Fitting estimator number 67\n",
      "Fitting estimator number 68\n",
      "Fitting estimator number 69\n",
      "Fitting estimator number 70\n",
      "Fitting estimator number 71\n",
      "Fitting estimator number 72\n",
      "Fitting estimator number 73\n",
      "Fitting estimator number 74\n",
      "Fitting estimator number 75\n",
      "Fitting estimator number 76\n",
      "Fitting estimator number 77\n",
      "Fitting estimator number 78\n",
      "Fitting estimator number 79\n",
      "Fitting estimator number 80\n",
      "Fitting estimator number 81\n",
      "Fitting estimator number 82\n",
      "Fitting estimator number 83\n",
      "Fitting estimator number 84\n",
      "Fitting estimator number 85\n",
      "Fitting estimator number 86\n",
      "Fitting estimator number 87\n",
      "Fitting estimator number 88\n",
      "Fitting estimator number 89\n",
      "Fitting estimator number 90\n",
      "Fitting estimator number 91\n",
      "Fitting estimator number 92\n",
      "Fitting estimator number 93\n",
      "Fitting estimator number 94\n",
      "Fitting estimator number 95\n",
      "Fitting estimator number 96\n",
      "Fitting estimator number 97\n",
      "Fitting estimator number 98\n",
      "Fitting estimator number 99\n",
      "Fitting estimator number 100\n",
      "Fitting estimator number 101\n",
      "Fitting estimator number 102\n",
      "Fitting estimator number 103\n",
      "Fitting estimator number 104\n",
      "Fitting estimator number 105\n",
      "Fitting estimator number 106\n",
      "Fitting estimator number 107\n",
      "Fitting estimator number 108\n",
      "Fitting estimator number 109\n",
      "Fitting estimator number 110\n",
      "Fitting estimator number 111\n",
      "Fitting estimator number 112\n",
      "Fitting estimator number 113\n",
      "Fitting estimator number 114\n",
      "Fitting estimator number 115\n",
      "Fitting estimator number 116\n",
      "Fitting estimator number 117\n",
      "Fitting estimator number 118\n",
      "Fitting estimator number 119\n",
      "Fitting estimator number 120\n",
      "Fitting estimator number 121\n",
      "Fitting estimator number 122\n",
      "Fitting estimator number 123\n",
      "Fitting estimator number 124\n",
      "Fitting estimator number 125\n",
      "Fitting estimator number 126\n",
      "Fitting estimator number 127\n",
      "Fitting estimator number 128\n",
      "Fitting estimator number 129\n",
      "Fitting estimator number 130\n",
      "Fitting estimator number 131\n",
      "Fitting estimator number 132\n",
      "Fitting estimator number 133\n",
      "Fitting estimator number 134\n",
      "Fitting estimator number 135\n",
      "Fitting estimator number 136\n",
      "Fitting estimator number 137\n",
      "Fitting estimator number 138\n",
      "Fitting estimator number 139\n",
      "Fitting estimator number 140\n",
      "Fitting estimator number 141\n",
      "Fitting estimator number 142\n",
      "Fitting estimator number 143\n",
      "Fitting estimator number 144\n",
      "Fitting estimator number 145\n",
      "Fitting estimator number 146\n",
      "Fitting estimator number 147\n",
      "Fitting estimator number 148\n",
      "Fitting estimator number 149\n",
      "Fitting estimator number 150\n",
      "Fitting estimator number 151\n",
      "Fitting estimator number 152\n",
      "Fitting estimator number 153\n",
      "Fitting estimator number 154\n",
      "Fitting estimator number 155\n",
      "Fitting estimator number 156\n",
      "Fitting estimator number 157\n",
      "Fitting estimator number 158\n",
      "Fitting estimator number 159\n",
      "Fitting estimator number 160\n",
      "Fitting estimator number 161\n",
      "Fitting estimator number 162\n",
      "Fitting estimator number 163\n",
      "Fitting estimator number 164\n",
      "Fitting estimator number 165\n",
      "Fitting estimator number 166\n",
      "Fitting estimator number 167\n",
      "Fitting estimator number 168\n",
      "Fitting estimator number 169\n",
      "Fitting estimator number 170\n",
      "Fitting estimator number 171\n",
      "Fitting estimator number 172\n",
      "Fitting estimator number 173\n",
      "Fitting estimator number 174\n",
      "Fitting estimator number 175\n",
      "Fitting estimator number 176\n",
      "Fitting estimator number 177\n",
      "Fitting estimator number 178\n",
      "Fitting estimator number 179\n",
      "Fitting estimator number 180\n",
      "Fitting estimator number 181\n",
      "Fitting estimator number 182\n",
      "Fitting estimator number 183\n",
      "Fitting estimator number 184\n",
      "Fitting estimator number 185\n",
      "Fitting estimator number 186\n",
      "Fitting estimator number 187\n",
      "Fitting estimator number 188\n",
      "Fitting estimator number 189\n",
      "Fitting estimator number 190\n",
      "Fitting estimator number 191\n",
      "Fitting estimator number 192\n",
      "Fitting estimator number 193\n",
      "Fitting estimator number 194\n",
      "Fitting estimator number 195\n",
      "Fitting estimator number 196\n",
      "Fitting estimator number 197\n",
      "Fitting estimator number 198\n",
      "Fitting estimator number 199\n",
      "Fitting estimator number 200\n",
      "Fitting estimator number 201\n",
      "Fitting estimator number 202\n",
      "Fitting estimator number 203\n",
      "Fitting estimator number 204\n",
      "Fitting estimator number 205\n",
      "Fitting estimator number 206\n",
      "Fitting estimator number 207\n",
      "Fitting estimator number 208\n",
      "Fitting estimator number 209\n",
      "Fitting estimator number 210\n",
      "Fitting estimator number 211\n",
      "Fitting estimator number 212\n",
      "Fitting estimator number 213\n",
      "Fitting estimator number 214\n",
      "Fitting estimator number 215\n",
      "Fitting estimator number 216\n",
      "Fitting estimator number 217\n",
      "Fitting estimator number 218\n",
      "Fitting estimator number 219\n",
      "Fitting estimator number 220\n",
      "Fitting estimator number 221\n",
      "Fitting estimator number 222\n",
      "Fitting estimator number 223\n",
      "Fitting estimator number 224\n",
      "Fitting estimator number 225\n",
      "Fitting estimator number 226\n",
      "Fitting estimator number 227\n",
      "Fitting estimator number 228\n",
      "Fitting estimator number 229\n",
      "Fitting estimator number 230\n",
      "Fitting estimator number 231\n",
      "Fitting estimator number 232\n",
      "Fitting estimator number 233\n",
      "Fitting estimator number 234\n",
      "Fitting estimator number 235\n",
      "Fitting estimator number 236\n",
      "Fitting estimator number 237\n",
      "Fitting estimator number 238\n",
      "Fitting estimator number 239\n",
      "Fitting estimator number 240\n",
      "Fitting estimator number 241\n",
      "Fitting estimator number 242\n",
      "Fitting estimator number 243\n",
      "Fitting estimator number 244\n",
      "Fitting estimator number 245\n",
      "Fitting estimator number 246\n",
      "Fitting estimator number 247\n",
      "Fitting estimator number 248\n",
      "Fitting estimator number 249\n",
      "Fitting estimator number 250\n",
      "Fitting estimator number 251\n",
      "Fitting estimator number 252\n",
      "Fitting estimator number 253\n",
      "Fitting estimator number 254\n",
      "Fitting estimator number 255\n",
      "Fitting estimator number 256\n",
      "Fitting estimator number 257\n",
      "Fitting estimator number 258\n",
      "Fitting estimator number 259\n",
      "Fitting estimator number 260\n",
      "Fitting estimator number 261\n",
      "Fitting estimator number 262\n",
      "Fitting estimator number 263\n",
      "Fitting estimator number 264\n",
      "Fitting estimator number 265\n",
      "Fitting estimator number 266\n",
      "Fitting estimator number 267\n",
      "Fitting estimator number 268\n",
      "Fitting estimator number 269\n",
      "Fitting estimator number 270\n",
      "Fitting estimator number 271\n",
      "Fitting estimator number 272\n",
      "Fitting estimator number 273\n",
      "Fitting estimator number 274\n",
      "Fitting estimator number 275\n",
      "Fitting estimator number 276\n",
      "Fitting estimator number 277\n",
      "Fitting estimator number 278\n",
      "Fitting estimator number 279\n",
      "Fitting estimator number 280\n",
      "Fitting estimator number 281\n",
      "Fitting estimator number 282\n",
      "Fitting estimator number 283\n",
      "Fitting estimator number 284\n",
      "Fitting estimator number 285\n",
      "Fitting estimator number 286\n",
      "Fitting estimator number 287\n",
      "Fitting estimator number 288\n",
      "Fitting estimator number 289\n",
      "Fitting estimator number 290\n",
      "Fitting estimator number 291\n",
      "Fitting estimator number 292\n",
      "Fitting estimator number 293\n",
      "Fitting estimator number 294\n",
      "Fitting estimator number 295\n",
      "Fitting estimator number 296\n",
      "Fitting estimator number 297\n",
      "Fitting estimator number 298\n",
      "Fitting estimator number 299\n",
      "Fitting estimator number 300\n",
      "OOB score: 0.909595061761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForest(n_estimators=300, max_depth=5, poi=1.0, pof=1.0)\n",
    "forest_clf.fit(spam_X_train, spam_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "forest_loss = []\n",
    "forest_f1 = []\n",
    "\n",
    "for e in forest_clf.estimators:\n",
    "    pr = e.predict(spam_X_test)\n",
    "    s += pr\n",
    "    p = np.sign(s)\n",
    "    forest_loss.append(log_loss(spam_y_test, p))    \n",
    "    forest_f1.append(f1_score(np.array((spam_y_test+1)/2, dtype=int),\n",
    "                              np.array((p+1)/2, dtype=int)))\n",
    "\n",
    "forest_sk_loss = []\n",
    "forest_sk_f1 = []\n",
    "\n",
    "forest_tree = RandomForestClassifier(max_depth=5, random_state=1, max_features=forest_clf.pof, warm_start=True)\n",
    "for i in xrange(3, forest_clf.n_estimators):\n",
    "    print i\n",
    "    forest_tree.set_params(n_estimators=i)\n",
    "    forest_tree.fit(spam_X_train, spam_y_train)\n",
    "    p = forest_tree.predict(spam_X_test)    \n",
    "    \n",
    "    forest_sk_loss.append(log_loss(spam_y_test, p))\n",
    "    forest_sk_f1.append(f1_score(np.array((spam_y_test+1)/2, dtype=int), \n",
    "                                 np.array((p+1)/2, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEKCAYAAADdBdT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6516ceea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(forest_loss, label='my', color='g')\n",
    "\n",
    "plt.plot(forest_sk_loss, label='sklearn', color='r')\n",
    "plt.plot(np.array(forest_sk_loss) * 1.03, label='+3%', color='r', alpha=0.5)\n",
    "plt.plot(np.array(forest_sk_loss) * 0.97, label='-3%', color='r', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Log loss vs n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEKCAYAAAD6q1UVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6510c9b310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(forest_f1, label='my', color='g')\n",
    "\n",
    "plt.plot(forest_sk_f1, label='sklearn', color='r')\n",
    "plt.plot(np.array(forest_sk_f1) * 1.03, label='+3%', color='r', alpha=0.5)\n",
    "plt.plot(np.array(forest_sk_f1) * 0.97, label='-3%', color='r', alpha=0.5)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"F1 score vs n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.868138424821\n",
      "precision =  0.796685961755\n",
      "recall =  0.885110925862\n",
      "f1 =  0.824854182961\n"
     ]
    }
   ],
   "source": [
    "forest_pred = forest_clf.predict(spam_X_test)\n",
    "\n",
    "print \"score: \", forest_clf.score(spam_X_test, spam_y_test)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(np.array((spam_y_test+1)/2, dtype=int),\n",
    "                                             np.array((forest_pred+1)/2, dtype=int))\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "print \"f1 = \", f.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.801788302442\n",
      "recall =  0.882783995521\n",
      "f1 =  0.82935880974\n"
     ]
    }
   ],
   "source": [
    "forest_tree_pred = forest_tree.predict(spam_X_test)\n",
    "p, r, f, _ = precision_recall_fscore_support(spam_y_test, forest_tree_pred)\n",
    "\n",
    "#print \"score: \", tree.score(spam_X_test, spam_y_test)\n",
    "\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "print \"f1 = \", f.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting gradient boosting with 300 estimators\n",
      "Fitting estimator number 1\n",
      "Score:  0.800930494854\n",
      "Loss: 6.87575037273\n",
      "diff: 6.87575037273\n",
      "Fitting estimator number 2\n",
      "Score:  0.800930494854\n",
      "Loss: 6.87575037273\n",
      "diff: 0.0\n",
      "Fitting estimator number 3\n",
      "Score:  0.891442267024\n",
      "Loss: 3.74948429524\n",
      "diff: -3.12626607749\n",
      "Fitting estimator number 4\n",
      "Score:  0.907232482729\n",
      "Loss: 3.20411091852\n",
      "diff: -0.545373376718\n",
      "Fitting estimator number 5\n",
      "Score:  0.91540955872\n",
      "Loss: 2.92167479904\n",
      "diff: -0.282436119481\n",
      "Fitting estimator number 6\n",
      "Score:  0.915691526857\n",
      "Loss: 2.91193438636\n",
      "diff: -0.00974041268206\n",
      "Fitting estimator number 7\n",
      "Score:  0.91653743127\n",
      "Loss: 2.88271405016\n",
      "diff: -0.0292203362022\n",
      "Fitting estimator number 8\n",
      "Score:  0.917524319752\n",
      "Loss: 2.84862779137\n",
      "diff: -0.0340862587842\n",
      "Fitting estimator number 9\n",
      "Score:  0.917524319752\n",
      "Loss: 2.84862779137\n",
      "diff: 0.0\n",
      "Fitting estimator number 10\n",
      "Score:  0.918229240096\n",
      "Loss: 2.82427845062\n",
      "diff: -0.0243493407477\n",
      "Fitting estimator number 11\n",
      "Score:  0.921048921472\n",
      "Loss: 2.72688852785\n",
      "diff: -0.0973899227777\n",
      "Fitting estimator number 12\n",
      "Score:  0.923727618779\n",
      "Loss: 2.63436824776\n",
      "diff: -0.0925202800892\n",
      "Fitting estimator number 13\n",
      "Score:  0.926688284224\n",
      "Loss: 2.53210992233\n",
      "diff: -0.102258325431\n",
      "Fitting estimator number 14\n",
      "Score:  0.927534188637\n",
      "Loss: 2.50289285531\n",
      "diff: -0.0292170670177\n",
      "Fitting estimator number 15\n",
      "Score:  0.928662061187\n",
      "Loss: 2.46393661564\n",
      "diff: -0.0389562396643\n",
      "Fitting estimator number 16\n",
      "Score:  0.931340758494\n",
      "Loss: 2.37141701194\n",
      "diff: -0.0925196037062\n",
      "Fitting estimator number 17\n",
      "Score:  0.933878471733\n",
      "Loss: 2.28376761457\n",
      "diff: -0.0876493973651\n",
      "Fitting estimator number 18\n",
      "Score:  0.935288312421\n",
      "Loss: 2.23507299138\n",
      "diff: -0.0486946231974\n",
      "Fitting estimator number 19\n",
      "Score:  0.935852248696\n",
      "Loss: 2.21559554793\n",
      "diff: -0.0194774434491\n",
      "Fitting estimator number 20\n",
      "Score:  0.937262089384\n",
      "Loss: 2.16690137565\n",
      "diff: -0.0486941722754\n",
      "Fitting estimator number 21\n",
      "Score:  0.937967009728\n",
      "Loss: 2.14255383859\n",
      "diff: -0.0243475370597\n",
      "Fitting estimator number 22\n",
      "Score:  0.937967009728\n",
      "Loss: 2.14255383859\n",
      "diff: 0.0\n",
      "Fitting estimator number 23\n",
      "Score:  0.93768504159\n",
      "Loss: 2.15229267305\n",
      "diff: 0.00973883445507\n",
      "Fitting estimator number 24\n",
      "Score:  0.937544057522\n",
      "Loss: 2.15716209027\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 25\n",
      "Score:  0.939235866347\n",
      "Loss: 2.09872908354\n",
      "diff: -0.0584330067304\n",
      "Fitting estimator number 26\n",
      "Score:  0.940645707035\n",
      "Loss: 2.05003434762\n",
      "diff: -0.0486947359279\n",
      "Fitting estimator number 27\n",
      "Score:  0.941773579586\n",
      "Loss: 2.01107878433\n",
      "diff: -0.0389555632813\n",
      "Fitting estimator number 28\n",
      "Score:  0.944452276893\n",
      "Loss: 1.91855951882\n",
      "diff: -0.0925192655147\n",
      "Fitting estimator number 29\n",
      "Score:  0.946285069787\n",
      "Loss: 1.85525675667\n",
      "diff: -0.0633027621495\n",
      "Fitting estimator number 30\n",
      "Score:  0.947271958269\n",
      "Loss: 1.82117072335\n",
      "diff: -0.0340860333232\n",
      "Fitting estimator number 31\n",
      "Score:  0.947412942338\n",
      "Loss: 1.81630119339\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 32\n",
      "Score:  0.948822783026\n",
      "Loss: 1.76760657019\n",
      "diff: -0.0486946231974\n",
      "Fitting estimator number 33\n",
      "Score:  0.948963767094\n",
      "Loss: 1.76273726569\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 34\n",
      "Score:  0.949809671507\n",
      "Loss: 1.73352042414\n",
      "diff: -0.0292168415567\n",
      "Fitting estimator number 35\n",
      "Score:  0.950091639645\n",
      "Loss: 1.72378147695\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 36\n",
      "Score:  0.951642464402\n",
      "Loss: 1.67021800018\n",
      "diff: -0.0535634767724\n",
      "Fitting estimator number 37\n",
      "Score:  0.952488368814\n",
      "Loss: 1.64100149681\n",
      "diff: -0.0292165033652\n",
      "Fitting estimator number 38\n",
      "Score:  0.952911321021\n",
      "Loss: 1.62639301967\n",
      "diff: -0.0146084771436\n",
      "Fitting estimator number 39\n",
      "Score:  0.952911321021\n",
      "Loss: 1.62639301967\n",
      "diff: 0.0\n",
      "Fitting estimator number 40\n",
      "Score:  0.952770336952\n",
      "Loss: 1.6312624369\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 41\n",
      "Score:  0.952770336952\n",
      "Loss: 1.63126254963\n",
      "diff: 1.12730499158e-07\n",
      "Fitting estimator number 42\n",
      "Score:  0.952911321021\n",
      "Loss: 1.6263931324\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 43\n",
      "Score:  0.95305230509\n",
      "Loss: 1.62152360244\n",
      "diff: -0.00486952995804\n",
      "Fitting estimator number 44\n",
      "Score:  0.954039193571\n",
      "Loss: 1.58743745639\n",
      "diff: -0.0340861460537\n",
      "Fitting estimator number 45\n",
      "Score:  0.954321161709\n",
      "Loss: 1.57769862193\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 46\n",
      "Score:  0.954462145778\n",
      "Loss: 1.57282920471\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 47\n",
      "Score:  0.954744113915\n",
      "Loss: 1.56309003206\n",
      "diff: -0.00973917264657\n",
      "Fitting estimator number 48\n",
      "Score:  0.954885097984\n",
      "Loss: 1.55822072756\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 49\n",
      "Score:  0.95530805019\n",
      "Loss: 1.54361247588\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 50\n",
      "Score:  0.956435922741\n",
      "Loss: 1.5046569126\n",
      "diff: -0.0389555632813\n",
      "Fitting estimator number 51\n",
      "Score:  0.956717890878\n",
      "Loss: 1.49491807814\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 52\n",
      "Score:  0.956999859016\n",
      "Loss: 1.48517924369\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 53\n",
      "Score:  0.957422811222\n",
      "Loss: 1.47057099201\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 54\n",
      "Score:  0.957422811222\n",
      "Loss: 1.47057099201\n",
      "diff: 0.0\n",
      "Fitting estimator number 55\n",
      "Score:  0.957563795291\n",
      "Loss: 1.46570157478\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 56\n",
      "Score:  0.957563795291\n",
      "Loss: 1.46570157478\n",
      "diff: 0.0\n",
      "Fitting estimator number 57\n",
      "Score:  0.957845763429\n",
      "Loss: 1.45596274032\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 58\n",
      "Score:  0.957845763429\n",
      "Loss: 1.45596274032\n",
      "diff: 0.0\n",
      "Fitting estimator number 59\n",
      "Score:  0.95770477936\n",
      "Loss: 1.46083215755\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 60\n",
      "Score:  0.957845763429\n",
      "Loss: 1.45596274032\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 61\n",
      "Score:  0.958127731566\n",
      "Loss: 1.44622379314\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 62\n",
      "Score:  0.958691667842\n",
      "Loss: 1.42674589877\n",
      "diff: -0.0194778943711\n",
      "Fitting estimator number 63\n",
      "Score:  0.960524460736\n",
      "Loss: 1.36344347481\n",
      "diff: -0.063302423958\n",
      "Fitting estimator number 64\n",
      "Score:  0.961088397011\n",
      "Loss: 1.34396569317\n",
      "diff: -0.0194777816406\n",
      "Fitting estimator number 65\n",
      "Score:  0.961088397011\n",
      "Loss: 1.34396569317\n",
      "diff: 0.0\n",
      "Fitting estimator number 66\n",
      "Score:  0.960947412942\n",
      "Loss: 1.34883499767\n",
      "diff: 0.00486930449704\n",
      "Fitting estimator number 67\n",
      "Score:  0.961370365149\n",
      "Loss: 1.33422685871\n",
      "diff: -0.0146081389521\n",
      "Fitting estimator number 68\n",
      "Score:  0.961511349218\n",
      "Loss: 1.32935732876\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 69\n",
      "Score:  0.961511349218\n",
      "Loss: 1.32935721603\n",
      "diff: -1.12730498936e-07\n",
      "Fitting estimator number 70\n",
      "Score:  0.962216269562\n",
      "Loss: 1.30501012989\n",
      "diff: -0.0243470861377\n",
      "Fitting estimator number 71\n",
      "Score:  0.962216269562\n",
      "Loss: 1.30501001716\n",
      "diff: -1.12730499158e-07\n",
      "Fitting estimator number 72\n",
      "Score:  0.962498237699\n",
      "Loss: 1.29527106997\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 73\n",
      "Score:  0.962498237699\n",
      "Loss: 1.29527084451\n",
      "diff: -2.25460998315e-07\n",
      "Fitting estimator number 74\n",
      "Score:  0.962639221768\n",
      "Loss: 1.29040154001\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 75\n",
      "Score:  0.963203158043\n",
      "Loss: 1.2709238711\n",
      "diff: -0.0194776689101\n",
      "Fitting estimator number 76\n",
      "Score:  0.963485126181\n",
      "Loss: 1.26118492392\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 77\n",
      "Score:  0.964049062456\n",
      "Loss: 1.24170714228\n",
      "diff: -0.0194777816406\n",
      "Fitting estimator number 78\n",
      "Score:  0.964472014662\n",
      "Loss: 1.22709866513\n",
      "diff: -0.0146084771436\n",
      "Fitting estimator number 79\n",
      "Score:  0.964472014662\n",
      "Loss: 1.22709866513\n",
      "diff: 0.0\n",
      "Fitting estimator number 80\n",
      "Score:  0.964331030594\n",
      "Loss: 1.23196808236\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 81\n",
      "Score:  0.964190046525\n",
      "Loss: 1.23683749959\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 82\n",
      "Score:  0.965035950938\n",
      "Loss: 1.20762088349\n",
      "diff: -0.0292166160957\n",
      "Fitting estimator number 83\n",
      "Score:  0.965317919075\n",
      "Loss: 1.19788204904\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 84\n",
      "Score:  0.965599887213\n",
      "Loss: 1.18814298912\n",
      "diff: -0.00973905991607\n",
      "Fitting estimator number 85\n",
      "Score:  0.965740871282\n",
      "Loss: 1.18327357189\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 86\n",
      "Score:  0.966022839419\n",
      "Loss: 1.17353462471\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 87\n",
      "Score:  0.966586775694\n",
      "Loss: 1.15405673034\n",
      "diff: -0.0194778943711\n",
      "Fitting estimator number 88\n",
      "Score:  0.96715071197\n",
      "Loss: 1.1345789487\n",
      "diff: -0.0194777816406\n",
      "Fitting estimator number 89\n",
      "Score:  0.96715071197\n",
      "Loss: 1.1345789487\n",
      "diff: 0.0\n",
      "Fitting estimator number 90\n",
      "Score:  0.96715071197\n",
      "Loss: 1.1345789487\n",
      "diff: 0.0\n",
      "Fitting estimator number 91\n",
      "Score:  0.966868743832\n",
      "Loss: 1.14431778315\n",
      "diff: 0.00973883445507\n",
      "Fitting estimator number 92\n",
      "Score:  0.966868743832\n",
      "Loss: 1.14431778315\n",
      "diff: 0.0\n",
      "Fitting estimator number 93\n",
      "Score:  0.966727759763\n",
      "Loss: 1.14918720038\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 94\n",
      "Score:  0.967291696038\n",
      "Loss: 1.12970941874\n",
      "diff: -0.0194777816406\n",
      "Fitting estimator number 95\n",
      "Score:  0.967432680107\n",
      "Loss: 1.12483988878\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 96\n",
      "Score:  0.967432680107\n",
      "Loss: 1.12483988878\n",
      "diff: 0.0\n",
      "Fitting estimator number 97\n",
      "Score:  0.967432680107\n",
      "Loss: 1.12483988878\n",
      "diff: 0.0\n",
      "Fitting estimator number 98\n",
      "Score:  0.967291696038\n",
      "Loss: 1.12970941874\n",
      "diff: 0.00486952995804\n",
      "Fitting estimator number 99\n",
      "Score:  0.967291696038\n",
      "Loss: 1.12970953147\n",
      "diff: 1.12730498936e-07\n",
      "Fitting estimator number 100\n",
      "Score:  0.967714648245\n",
      "Loss: 1.11510116706\n",
      "diff: -0.0146083644131\n",
      "Fitting estimator number 101\n",
      "Score:  0.967714648245\n",
      "Loss: 1.11510116706\n",
      "diff: 0.0\n",
      "Fitting estimator number 102\n",
      "Score:  0.967573664176\n",
      "Loss: 1.11997058428\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 103\n",
      "Score:  0.967573664176\n",
      "Loss: 1.11997058428\n",
      "diff: 0.0\n",
      "Fitting estimator number 104\n",
      "Score:  0.967573664176\n",
      "Loss: 1.11997069701\n",
      "diff: 1.12730498936e-07\n",
      "Fitting estimator number 105\n",
      "Score:  0.967855632314\n",
      "Loss: 1.11023174983\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 106\n",
      "Score:  0.967855632314\n",
      "Loss: 1.11023174983\n",
      "diff: 0.0\n",
      "Fitting estimator number 107\n",
      "Score:  0.968137600451\n",
      "Loss: 1.10049257718\n",
      "diff: -0.00973917264657\n",
      "Fitting estimator number 108\n",
      "Score:  0.96827858452\n",
      "Loss: 1.09562315995\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 109\n",
      "Score:  0.96827858452\n",
      "Loss: 1.09562315995\n",
      "diff: 0.0\n",
      "Fitting estimator number 110\n",
      "Score:  0.968137600451\n",
      "Loss: 1.10049257718\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 111\n",
      "Score:  0.96827858452\n",
      "Loss: 1.09562315995\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 112\n",
      "Score:  0.968419568589\n",
      "Loss: 1.09075374273\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 113\n",
      "Score:  0.968419568589\n",
      "Loss: 1.09075374273\n",
      "diff: 0.0\n",
      "Fitting estimator number 114\n",
      "Score:  0.96827858452\n",
      "Loss: 1.09562315995\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 115\n",
      "Score:  0.96827858452\n",
      "Loss: 1.09562315995\n",
      "diff: 0.0\n",
      "Fitting estimator number 116\n",
      "Score:  0.968419568589\n",
      "Loss: 1.09075374273\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 117\n",
      "Score:  0.968560552658\n",
      "Loss: 1.08588443823\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 118\n",
      "Score:  0.968560552658\n",
      "Loss: 1.08588443823\n",
      "diff: 0.0\n",
      "Fitting estimator number 119\n",
      "Score:  0.969124488933\n",
      "Loss: 1.06640665659\n",
      "diff: -0.0194777816406\n",
      "Fitting estimator number 120\n",
      "Score:  0.969124488933\n",
      "Loss: 1.06640665659\n",
      "diff: 0.0\n",
      "Fitting estimator number 121\n",
      "Score:  0.969970393346\n",
      "Loss: 1.03719015322\n",
      "diff: -0.0292165033652\n",
      "Fitting estimator number 122\n",
      "Score:  0.970111377414\n",
      "Loss: 1.032320736\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 123\n",
      "Score:  0.970816297758\n",
      "Loss: 1.00797364986\n",
      "diff: -0.0243470861377\n",
      "Fitting estimator number 124\n",
      "Score:  0.970816297758\n",
      "Loss: 1.00797364986\n",
      "diff: 0.0\n",
      "Fitting estimator number 125\n",
      "Score:  0.97067531369\n",
      "Loss: 1.01284306709\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 126\n",
      "Score:  0.971098265896\n",
      "Loss: 0.998234815404\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 127\n",
      "Score:  0.971239249965\n",
      "Loss: 0.993365398176\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 128\n",
      "Score:  0.971239249965\n",
      "Loss: 0.993365398176\n",
      "diff: 0.0\n",
      "Fitting estimator number 129\n",
      "Score:  0.971521218102\n",
      "Loss: 0.983626450991\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 130\n",
      "Score:  0.971521218102\n",
      "Loss: 0.983626450991\n",
      "diff: 0.0\n",
      "Fitting estimator number 131\n",
      "Score:  0.971380234034\n",
      "Loss: 0.988495980949\n",
      "diff: 0.00486952995803\n",
      "Fitting estimator number 132\n",
      "Score:  0.971662202171\n",
      "Loss: 0.978757033763\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 133\n",
      "Score:  0.97180318624\n",
      "Loss: 0.973887503805\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 134\n",
      "Score:  0.971944170309\n",
      "Loss: 0.969018086578\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 135\n",
      "Score:  0.972226138446\n",
      "Loss: 0.959279252123\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 136\n",
      "Score:  0.972226138446\n",
      "Loss: 0.959279252123\n",
      "diff: 0.0\n",
      "Fitting estimator number 137\n",
      "Score:  0.972226138446\n",
      "Loss: 0.959279252123\n",
      "diff: 0.0\n",
      "Fitting estimator number 138\n",
      "Score:  0.972367122515\n",
      "Loss: 0.954409722164\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 139\n",
      "Score:  0.972790074722\n",
      "Loss: 0.939801357751\n",
      "diff: -0.0146083644131\n",
      "Fitting estimator number 140\n",
      "Score:  0.972790074722\n",
      "Loss: 0.939801357751\n",
      "diff: 0.0\n",
      "Fitting estimator number 141\n",
      "Score:  0.973213026928\n",
      "Loss: 0.925193106069\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 142\n",
      "Score:  0.973213026928\n",
      "Loss: 0.925193106069\n",
      "diff: 0.0\n",
      "Fitting estimator number 143\n",
      "Score:  0.973072042859\n",
      "Loss: 0.930062523296\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 144\n",
      "Score:  0.973213026928\n",
      "Loss: 0.925193106069\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 145\n",
      "Score:  0.973213026928\n",
      "Loss: 0.925193106069\n",
      "diff: 0.0\n",
      "Fitting estimator number 146\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 147\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 0.0\n",
      "Fitting estimator number 148\n",
      "Score:  0.973635979134\n",
      "Loss: 0.910584854386\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 149\n",
      "Score:  0.973635979134\n",
      "Loss: 0.910584854386\n",
      "diff: 0.0\n",
      "Fitting estimator number 150\n",
      "Score:  0.973635979134\n",
      "Loss: 0.910584854386\n",
      "diff: 0.0\n",
      "Fitting estimator number 151\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 152\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: -1.11022302463e-16\n",
      "Fitting estimator number 153\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 0.0\n",
      "Fitting estimator number 154\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 0.0\n",
      "Fitting estimator number 155\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 1.11022302463e-16\n",
      "Fitting estimator number 156\n",
      "Score:  0.973494995066\n",
      "Loss: 0.915454271614\n",
      "diff: 0.0\n",
      "Fitting estimator number 157\n",
      "Score:  0.973354010997\n",
      "Loss: 0.920323688841\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 158\n",
      "Score:  0.974058931341\n",
      "Loss: 0.895976602704\n",
      "diff: -0.0243470861377\n",
      "Fitting estimator number 159\n",
      "Score:  0.97419991541\n",
      "Loss: 0.891107185476\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 160\n",
      "Score:  0.974481883547\n",
      "Loss: 0.881368351021\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 161\n",
      "Score:  0.974481883547\n",
      "Loss: 0.881368351021\n",
      "diff: 0.0\n",
      "Fitting estimator number 162\n",
      "Score:  0.974481883547\n",
      "Loss: 0.88136823829\n",
      "diff: -1.12730499047e-07\n",
      "Fitting estimator number 163\n",
      "Score:  0.974622867616\n",
      "Loss: 0.876498821063\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 164\n",
      "Score:  0.974904835754\n",
      "Loss: 0.866759986608\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 165\n",
      "Score:  0.974904835754\n",
      "Loss: 0.866759986608\n",
      "diff: 0.0\n",
      "Fitting estimator number 166\n",
      "Score:  0.974904835754\n",
      "Loss: 0.866759986608\n",
      "diff: 0.0\n",
      "Fitting estimator number 167\n",
      "Score:  0.974763851685\n",
      "Loss: 0.871629403835\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 168\n",
      "Score:  0.974763851685\n",
      "Loss: 0.871629403835\n",
      "diff: 0.0\n",
      "Fitting estimator number 169\n",
      "Score:  0.974622867616\n",
      "Loss: 0.876498821063\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 170\n",
      "Score:  0.974763851685\n",
      "Loss: 0.871629403835\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 171\n",
      "Score:  0.975045819822\n",
      "Loss: 0.86189045665\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 172\n",
      "Score:  0.975468772029\n",
      "Loss: 0.847281866776\n",
      "diff: -0.0146085898741\n",
      "Fitting estimator number 173\n",
      "Score:  0.975468772029\n",
      "Loss: 0.847281866776\n",
      "diff: 0.0\n",
      "Fitting estimator number 174\n",
      "Score:  0.97532778796\n",
      "Loss: 0.852151396734\n",
      "diff: 0.00486952995803\n",
      "Fitting estimator number 175\n",
      "Score:  0.975186803891\n",
      "Loss: 0.857020926692\n",
      "diff: 0.00486952995803\n",
      "Fitting estimator number 176\n",
      "Score:  0.97532778796\n",
      "Loss: 0.852151396734\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 177\n",
      "Score:  0.975750740166\n",
      "Loss: 0.837543032321\n",
      "diff: -0.0146083644131\n",
      "Fitting estimator number 178\n",
      "Score:  0.975750740166\n",
      "Loss: 0.837543032321\n",
      "diff: 0.0\n",
      "Fitting estimator number 179\n",
      "Score:  0.975750740166\n",
      "Loss: 0.837543032321\n",
      "diff: 0.0\n",
      "Fitting estimator number 180\n",
      "Score:  0.975609756098\n",
      "Loss: 0.842412449548\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 181\n",
      "Score:  0.975891724235\n",
      "Loss: 0.832673502363\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 182\n",
      "Score:  0.976032708304\n",
      "Loss: 0.827804197866\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 183\n",
      "Score:  0.976032708304\n",
      "Loss: 0.827804085135\n",
      "diff: -1.12730499158e-07\n",
      "Fitting estimator number 184\n",
      "Score:  0.976314676442\n",
      "Loss: 0.81806536341\n",
      "diff: -0.00973872172457\n",
      "Fitting estimator number 185\n",
      "Score:  0.97645566051\n",
      "Loss: 0.813195946183\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 186\n",
      "Score:  0.97645566051\n",
      "Loss: 0.813195946183\n",
      "diff: 0.0\n",
      "Fitting estimator number 187\n",
      "Score:  0.97645566051\n",
      "Loss: 0.813195946183\n",
      "diff: 0.0\n",
      "Fitting estimator number 188\n",
      "Score:  0.976878612717\n",
      "Loss: 0.798587807231\n",
      "diff: -0.0146081389521\n",
      "Fitting estimator number 189\n",
      "Score:  0.976878612717\n",
      "Loss: 0.7985876945\n",
      "diff: -1.12730499269e-07\n",
      "Fitting estimator number 190\n",
      "Score:  0.976878612717\n",
      "Loss: 0.7985876945\n",
      "diff: 0.0\n",
      "Fitting estimator number 191\n",
      "Score:  0.976737628648\n",
      "Loss: 0.803457111728\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 192\n",
      "Score:  0.977442548992\n",
      "Loss: 0.77910991286\n",
      "diff: -0.0243471988682\n",
      "Fitting estimator number 193\n",
      "Score:  0.977442548992\n",
      "Loss: 0.77910991286\n",
      "diff: 0.0\n",
      "Fitting estimator number 194\n",
      "Score:  0.977442548992\n",
      "Loss: 0.77910991286\n",
      "diff: 0.0\n",
      "Fitting estimator number 195\n",
      "Score:  0.977301564923\n",
      "Loss: 0.783979330087\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 196\n",
      "Score:  0.977301564923\n",
      "Loss: 0.783979330087\n",
      "diff: 0.0\n",
      "Fitting estimator number 197\n",
      "Score:  0.97772451713\n",
      "Loss: 0.769370740213\n",
      "diff: -0.0146085898741\n",
      "Fitting estimator number 198\n",
      "Score:  0.97772451713\n",
      "Loss: 0.769370740213\n",
      "diff: 0.0\n",
      "Fitting estimator number 199\n",
      "Score:  0.978147469336\n",
      "Loss: 0.7547623758\n",
      "diff: -0.0146083644131\n",
      "Fitting estimator number 200\n",
      "Score:  0.978147469336\n",
      "Loss: 0.7547623758\n",
      "diff: 0.0\n",
      "Fitting estimator number 201\n",
      "Score:  0.978147469336\n",
      "Loss: 0.7547623758\n",
      "diff: 0.0\n",
      "Fitting estimator number 202\n",
      "Score:  0.977865501198\n",
      "Loss: 0.764501210255\n",
      "diff: 0.00973883445507\n",
      "Fitting estimator number 203\n",
      "Score:  0.978006485267\n",
      "Loss: 0.759631793028\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 204\n",
      "Score:  0.978147469336\n",
      "Loss: 0.7547623758\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 205\n",
      "Score:  0.978570421542\n",
      "Loss: 0.740154124117\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 206\n",
      "Score:  0.978993373749\n",
      "Loss: 0.725545872435\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 207\n",
      "Score:  0.978993373749\n",
      "Loss: 0.725545872435\n",
      "diff: 0.0\n",
      "Fitting estimator number 208\n",
      "Score:  0.979134357818\n",
      "Loss: 0.720676342477\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 209\n",
      "Score:  0.979134357818\n",
      "Loss: 0.720676342477\n",
      "diff: 0.0\n",
      "Fitting estimator number 210\n",
      "Score:  0.979134357818\n",
      "Loss: 0.720676342477\n",
      "diff: 0.0\n",
      "Fitting estimator number 211\n",
      "Score:  0.979416325955\n",
      "Loss: 0.710937395291\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 212\n",
      "Score:  0.979416325955\n",
      "Loss: 0.710937395291\n",
      "diff: 0.0\n",
      "Fitting estimator number 213\n",
      "Score:  0.979698294093\n",
      "Loss: 0.701198560836\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 214\n",
      "Score:  0.980121246299\n",
      "Loss: 0.686590309154\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 215\n",
      "Score:  0.980262230368\n",
      "Loss: 0.681720891926\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 216\n",
      "Score:  0.980262230368\n",
      "Loss: 0.681720891926\n",
      "diff: 0.0\n",
      "Fitting estimator number 217\n",
      "Score:  0.980121246299\n",
      "Loss: 0.686590309154\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 218\n",
      "Score:  0.980262230368\n",
      "Loss: 0.681720891926\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 219\n",
      "Score:  0.980403214437\n",
      "Loss: 0.676851474698\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 220\n",
      "Score:  0.980685182574\n",
      "Loss: 0.667112640243\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 221\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 222\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.0\n",
      "Fitting estimator number 223\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.0\n",
      "Fitting estimator number 224\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.0\n",
      "Fitting estimator number 225\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.0\n",
      "Fitting estimator number 226\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.0\n",
      "Fitting estimator number 227\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243335746\n",
      "diff: 1.12730499158e-07\n",
      "Fitting estimator number 228\n",
      "Score:  0.980967150712\n",
      "Loss: 0.657373805788\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 229\n",
      "Score:  0.980967150712\n",
      "Loss: 0.657373805788\n",
      "diff: 0.0\n",
      "Fitting estimator number 230\n",
      "Score:  0.980826166643\n",
      "Loss: 0.662243223016\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 231\n",
      "Score:  0.980967150712\n",
      "Loss: 0.657373693058\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 232\n",
      "Score:  0.980967150712\n",
      "Loss: 0.657373693058\n",
      "diff: 0.0\n",
      "Fitting estimator number 233\n",
      "Score:  0.981108134781\n",
      "Loss: 0.65250427583\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 234\n",
      "Score:  0.981108134781\n",
      "Loss: 0.65250427583\n",
      "diff: 0.0\n",
      "Fitting estimator number 235\n",
      "Score:  0.981108134781\n",
      "Loss: 0.65250427583\n",
      "diff: 0.0\n",
      "Fitting estimator number 236\n",
      "Score:  0.98124911885\n",
      "Loss: 0.647634858603\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 237\n",
      "Score:  0.98124911885\n",
      "Loss: 0.647634858603\n",
      "diff: 0.0\n",
      "Fitting estimator number 238\n",
      "Score:  0.98124911885\n",
      "Loss: 0.647634858603\n",
      "diff: 0.0\n",
      "Fitting estimator number 239\n",
      "Score:  0.981672071056\n",
      "Loss: 0.63302660692\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 240\n",
      "Score:  0.981672071056\n",
      "Loss: 0.63302660692\n",
      "diff: 0.0\n",
      "Fitting estimator number 241\n",
      "Score:  0.981531086987\n",
      "Loss: 0.637896136878\n",
      "diff: 0.00486952995803\n",
      "Fitting estimator number 242\n",
      "Score:  0.981390102918\n",
      "Loss: 0.642765554106\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 243\n",
      "Score:  0.981390102918\n",
      "Loss: 0.642765554106\n",
      "diff: 0.0\n",
      "Fitting estimator number 244\n",
      "Score:  0.981390102918\n",
      "Loss: 0.642765441375\n",
      "diff: -1.12730499047e-07\n",
      "Fitting estimator number 245\n",
      "Score:  0.981390102918\n",
      "Loss: 0.642765441375\n",
      "diff: 0.0\n",
      "Fitting estimator number 246\n",
      "Score:  0.98124911885\n",
      "Loss: 0.647634858603\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 247\n",
      "Score:  0.981531086987\n",
      "Loss: 0.637896024148\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 248\n",
      "Score:  0.981954039194\n",
      "Loss: 0.623287659735\n",
      "diff: -0.0146083644131\n",
      "Fitting estimator number 249\n",
      "Score:  0.981954039194\n",
      "Loss: 0.623287659735\n",
      "diff: 0.0\n",
      "Fitting estimator number 250\n",
      "Score:  0.981954039194\n",
      "Loss: 0.623287659735\n",
      "diff: 0.0\n",
      "Fitting estimator number 251\n",
      "Score:  0.981954039194\n",
      "Loss: 0.623287659735\n",
      "diff: 0.0\n",
      "Fitting estimator number 252\n",
      "Score:  0.982095023262\n",
      "Loss: 0.618418242507\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 253\n",
      "Score:  0.982236007331\n",
      "Loss: 0.613548825279\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 254\n",
      "Score:  0.9823769914\n",
      "Loss: 0.608679408052\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 255\n",
      "Score:  0.9823769914\n",
      "Loss: 0.608679408052\n",
      "diff: 0.0\n",
      "Fitting estimator number 256\n",
      "Score:  0.9823769914\n",
      "Loss: 0.608679408052\n",
      "diff: 0.0\n",
      "Fitting estimator number 257\n",
      "Score:  0.9823769914\n",
      "Loss: 0.608679408052\n",
      "diff: 0.0\n",
      "Fitting estimator number 258\n",
      "Score:  0.9823769914\n",
      "Loss: 0.608679408052\n",
      "diff: -1.11022302463e-16\n",
      "Fitting estimator number 259\n",
      "Score:  0.982658959538\n",
      "Loss: 0.598940573597\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 260\n",
      "Score:  0.982940927675\n",
      "Loss: 0.589201626411\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 261\n",
      "Score:  0.982940927675\n",
      "Loss: 0.589201626411\n",
      "diff: 0.0\n",
      "Fitting estimator number 262\n",
      "Score:  0.982940927675\n",
      "Loss: 0.589201626411\n",
      "diff: 0.0\n",
      "Fitting estimator number 263\n",
      "Score:  0.983081911744\n",
      "Loss: 0.584332209184\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 264\n",
      "Score:  0.983222895813\n",
      "Loss: 0.579462791956\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 265\n",
      "Score:  0.983222895813\n",
      "Loss: 0.579462791956\n",
      "diff: 0.0\n",
      "Fitting estimator number 266\n",
      "Score:  0.983363879882\n",
      "Loss: 0.574593374729\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 267\n",
      "Score:  0.983363879882\n",
      "Loss: 0.574593374729\n",
      "diff: 0.0\n",
      "Fitting estimator number 268\n",
      "Score:  0.983363879882\n",
      "Loss: 0.574593374729\n",
      "diff: 0.0\n",
      "Fitting estimator number 269\n",
      "Score:  0.983645848019\n",
      "Loss: 0.564854540274\n",
      "diff: -0.00973883445507\n",
      "Fitting estimator number 270\n",
      "Score:  0.983645848019\n",
      "Loss: 0.564854540274\n",
      "diff: 0.0\n",
      "Fitting estimator number 271\n",
      "Score:  0.983786832088\n",
      "Loss: 0.559985123046\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 272\n",
      "Score:  0.983786832088\n",
      "Loss: 0.559985123046\n",
      "diff: 0.0\n",
      "Fitting estimator number 273\n",
      "Score:  0.983786832088\n",
      "Loss: 0.559985123046\n",
      "diff: 0.0\n",
      "Fitting estimator number 274\n",
      "Score:  0.983645848019\n",
      "Loss: 0.564854540274\n",
      "diff: 0.00486941722754\n",
      "Fitting estimator number 275\n",
      "Score:  0.983786832088\n",
      "Loss: 0.559985010316\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 276\n",
      "Score:  0.984209784294\n",
      "Loss: 0.545376758633\n",
      "diff: -0.0146082516826\n",
      "Fitting estimator number 277\n",
      "Score:  0.984350768363\n",
      "Loss: 0.540507228675\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 278\n",
      "Score:  0.984350768363\n",
      "Loss: 0.540507228675\n",
      "diff: 0.0\n",
      "Fitting estimator number 279\n",
      "Score:  0.984491752432\n",
      "Loss: 0.535637924178\n",
      "diff: -0.00486930449704\n",
      "Fitting estimator number 280\n",
      "Score:  0.984632736501\n",
      "Loss: 0.53076850695\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 281\n",
      "Score:  0.984632736501\n",
      "Loss: 0.53076850695\n",
      "diff: 0.0\n",
      "Fitting estimator number 282\n",
      "Score:  0.98477372057\n",
      "Loss: 0.525898976992\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 283\n",
      "Score:  0.985055688707\n",
      "Loss: 0.516160029807\n",
      "diff: -0.00973894718557\n",
      "Fitting estimator number 284\n",
      "Score:  0.985055688707\n",
      "Loss: 0.516160029807\n",
      "diff: 0.0\n",
      "Fitting estimator number 285\n",
      "Score:  0.985196672776\n",
      "Loss: 0.511290612579\n",
      "diff: -0.00486941722754\n",
      "Fitting estimator number 286\n",
      "Score:  0.985196672776\n",
      "Loss: 0.511290612579\n",
      "diff: 0.0\n",
      "Fitting estimator number 287\n",
      "Score:  0.985196672776\n",
      "Loss: 0.511290612579\n",
      "diff: 0.0\n",
      "Fitting estimator number 288\n",
      "Score:  0.985196672776\n",
      "Loss: 0.511290612579\n",
      "diff: 0.0\n",
      "Fitting estimator number 289\n",
      "Score:  0.985196672776\n",
      "Loss: 0.51129072531\n",
      "diff: 1.12730499047e-07\n",
      "Fitting estimator number 290\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 291\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: 0.0\n",
      "Fitting estimator number 292\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: 0.0\n",
      "Fitting estimator number 293\n",
      "Score:  0.985196672776\n",
      "Loss: 0.51129072531\n",
      "diff: 0.00486952995803\n",
      "Fitting estimator number 294\n",
      "Score:  0.985196672776\n",
      "Loss: 0.51129072531\n",
      "diff: 0.0\n",
      "Fitting estimator number 295\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 296\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: 0.0\n",
      "Fitting estimator number 297\n",
      "Score:  0.985337656845\n",
      "Loss: 0.506421195352\n",
      "diff: 0.0\n",
      "Fitting estimator number 298\n",
      "Score:  0.985478640914\n",
      "Loss: 0.501551665394\n",
      "diff: -0.00486952995803\n",
      "Fitting estimator number 299\n",
      "Score:  0.985478640914\n",
      "Loss: 0.501551665394\n",
      "diff: 0.0\n",
      "Fitting estimator number 300\n",
      "Score:  0.98590159312\n",
      "Loss: 0.486943413711\n",
      "diff: -0.0146082516826\n"
     ]
    }
   ],
   "source": [
    "grad_clf = GradientBoosting(n_estimators=300, max_depth=3, mu=0.01)\n",
    "grad_clf.fit(spam_X_train, spam_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98590159311997749"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clf.score(spam_X_train, spam_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 0.75, 0.23, 1.0, 0.99, 0.022000000000000006, 0.59, 0.9400000000000001, 0.77, 0.88, 0.85, 0.98, 0.98, 1.0, 0.15, 0.96, 1.0, 0.35000000000000003, 0.006, 0.05099999999999998, 0.42, 1.0, 0.8300000000000001, 1.0, 1.0, 0.74, 1.0, 0.72, 0.9400000000000001, 1.0, 1.0, 1.0, 0.96, 1.0, 0.41000000000000003, 0.008, 0.02700000000000001, 1.0, 0.58, 0.9500000000000001, 1.0, 0.74, 0.96, 1.0, 0.27, 0.65, 0.9, 0.81, 0.44, 0.66, 0.019000000000000006, 0.21, 0.64, 0.9500000000000001, 0.002, 0.72, 0.36, 1.0, 1.0, 1.0, 0.81, 0.006, 0.87, 0.9500000000000001, 0.85, 1.0, 1.0, 1.0, 0.6900000000000001, 0.81, 1.0, 1.0, 1.0, 0.88, 0.85, 0.001, 0.014000000000000002, 0.77, 1.0, 1.0, 0.88, 0.72, 1.0, 1.0, 0.5700000000000001, 0.34, 0.009999999999999998, 0.1, 0.002, 0.35000000000000003, 1.0, 1.0, 0.44, 0.1, 0.013000000000000001, 1.0, 0.49, 0.005, 0.2, 0.009, 0.34, 1.0, 0.07099999999999991, 1.0, 1.0, 0.07099999999999991, 1.0, 1.0, 0.8200000000000001, 0.0030000000000000005, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.55, 1.0, 1.0, 1.0, 0.09299999999999983, 0.79, 1.0, 1.0, 1.0, 0.99, 0.029000000000000012, 0.06099999999999994, 1.0, 1.0, 1.0, 1.0, 0.15, 0.96, 1.0, 1.0, 1.0, 1.0, 0.018000000000000006, 0.77, 0.45, 1.0, 0.6, 1.0, 1.0, 0.17, 0.005, 0.06899999999999992, 1.0, 0.28, 0.002, 0.52, 0.001, 0.48, 1.0, 1.0, 0.88, 0.85, 1.0, 1.0, 1.0, 0.31, 0.009, 0.25, 0.002, 1.0, 1.0, 1.0, 0.98, 0.004, 0.015000000000000003, 0.24, 1.0, 1.0, 0.55, 0.013000000000000001, 0.09299999999999983, 1.0, 0.81, 0.4, 1.0, 0.26, 1.0, 0.15, 1.0, 1.0, 0.07999999999999988, 0.030000000000000013, 1.0, 0.11, 0.009, 0.49, 1.0, 1.0, 1.0, 1.0, 0.13, 0.009, 0.87, 1.0, 1.0, 1.0, 1.0, 0.21, 1.0, 0.85, 1.0, 1.0, 1.0, 0.98, 1.0, 0.42, 0.008, 0.16, 0.8300000000000001, 0.48, 1.0, 1.0, 0.49, 0.36, 0.3, 0.14, 0.0030000000000000005, 0.85, 0.31, 0.011, 1.0, 1.0, 1.0, 1.0, 0.72, 0.86, 1.0, 0.33, 0.38, 1.0, 0.02700000000000001, 0.05899999999999995, 0.65, 0.7000000000000001, 0.12, 0.001, 1.0, 1.0, 1.0, 1.0, 0.64, 0.004, 1.0, 0.58, 1.0, 0.8, 0.27, 0.17, 1.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43, 1.0, 1.0, 1.0, 0.37, 0.006, 1.0, 1.0, 1.0, 1.0, 0.46, 1.0, 0.93, 1.0, 0.55, 1.0, 0.49, 1.0, 1.0, 0.71, 0.009, 1.0, 1.0, 0.61, 0.002, 1.0, 0.15, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print grad_clf.weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.95246618934\n",
      "precision =  0.918180868744\n",
      "recall =  0.939178673414\n",
      "f1 =  0.928150638209\n",
      "0.969948447127\n",
      "Log loss =  1.64177309554\n"
     ]
    }
   ],
   "source": [
    "grad_pred = grad_clf.predict(spam_X_test)\n",
    "grad_pred = np.sign(grad_pred)\n",
    "\n",
    "print \"score: \", grad_clf.score(spam_X_test, spam_y_test)\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(np.array((spam_y_test+1)/2, dtype=int),\n",
    "                                             np.array((grad_pred+1)/2, dtype=int))\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "#print \"f1 = \", f.mean()\n",
    "print \"f1 = \", f1_score(np.array((spam_y_test+1)/2, dtype=int), np.array((grad_pred+1)/2, dtype=int))\n",
    "\n",
    "print \"Log loss = \", log_loss((spam_y_test+1)/2., (grad_pred+1)/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-2ccd91e169b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrad_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpresort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrad_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspam_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "grad_tree = GradientBoostingClassifier(max_depth=3, n_estimators=300, learning_rate=0.01, random_state=1, presort=False)\n",
    "grad_tree.fit(spam_X_train, spam_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b23ad4df0da1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrad_tree_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_y_test\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrad_tree_pred\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspam_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grad_tree' is not defined"
     ]
    }
   ],
   "source": [
    "grad_tree_pred = grad_tree.predict(spam_X_test)\n",
    "p, r, f, _ = precision_recall_fscore_support((spam_y_test+1)/2., (grad_tree_pred+1)/2.)\n",
    "\n",
    "print \"score: \", grad_tree.score(spam_X_test, spam_y_test)\n",
    "\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "#print \"f1 = \", f.mean()\n",
    "print \"f1 = \", f1_score(np.array((spam_y_test+1)/2, dtype=int), np.array((grad_tree_pred+1)/2, dtype=int))\n",
    "\n",
    "print \"Log loss = \", log_loss((spam_y_test+1)/2., (grad_tree_pred+1)/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6516f9f150>]"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEACAYAAAB8nvebAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH+1JREFUeJzt3Xl0XXW5//H3k3lqkiZN0jEd6NxSCoWWtiApIiBKCxd/\nit6LIMryOlDUi6L+lpcCdynXmQuKKFRRpIheRRDrj0HSQmtbS+fWtumUtmnTNEkzz+d8f39kMJTM\n2cnJPvm81srqOWfvs/fzzW6fPuf57r2POecQERF/iQh1ACIi0ntK3iIiPqTkLSLiQ0reIiI+pOQt\nIuJDSt4iIj7UbfI2sxlmtr3dT7mZrRyM4EREpGPWm/O8zSwCKAAWOudODFhUIiLSpd62Ta4BDitx\ni4iEVm+T963AswMRiIiI9FyP2yZmFkNzy2S2c+7sgEYlIiJdiurFuu8H3j4/cZuZbo4iItIHzjnr\n63t70zb5KLCmkwDC9uf+++8PeQwan8Y3HMcXzmNzrv81b4+St5kl0jxZ+ft+71FERPqtR20T51w1\nMGqAYxERkR7SFZbdyMnJCXUIA0rj87dwHl84j80LvbpIp8MNmDkv+jciIsOJmeEGacJSRESGCCVv\nEREfGrTkXVpbOli7EhEJe4OWvKc9Oo2axprB2p2ISFgblOQdCAYorS1V8hYR8cigJO/WpF3bWDsY\nuxMRCXuDkryrG6sBqGuqG4zdiYiEvcFJ3g3Nybu2SZW3iIgX1DYREfEhtU1ERHxIbRMRER8a1LaJ\nKm8REW8MattEPW8REW+obSIi4kNqm4iI+JDaJiIiPqS2iYiID3mWvFeuXcnh0sMdLqtprCElNkVt\nExERj3iWvDcXbCa/PB9obo+U15W3LaturGZUwii1TUREPOJZ8g4EA22V9Y///mO+/OqX25ZVN1aT\nnpCuyltExCNRXm2oKdjUlpz/UfwP9hfvb1tW01hDeny6et4iIh7xrvJ2/6y880rz3pG8qxta2iZK\n3iIinvAsebevvPNK8iirK6OkpgRoaZvEq20iIuIVz5N3ZX0lZXVlXDzmYg6UHABa2iYJ6ZqwFBHx\niOcTlodKD3FB2gXMGjWLA8XNybu6QZW3iIiXPK+880rzmJY2jRnpM9oq79azTdTzFhHxRrfJ28xS\nzex3ZvYPM9tnZpd3tF7rhGVeSXPynpUxi11ndgHNbROd5y0i4p2eVN6PAH92zs0C5gH/6Gil1sq7\nqLqI0UmjWTZpGW8df4vqhmq1TUREPNbled5mlgJc6Zy7HcA51wSUd7Rua8+7prGGxJhERsaPZNH4\nRaw9tJaGQAOpcalqm4iIeKS7ynsycNbMfm5m28zsZ2aW0NGKrZV3dWM1idGJANw04yYe3fIoCdEJ\nJEQnqG0iIuKR7pJ3FHAJ8GPn3CVANfDVjlZs7XlXN1STGNOcvG+deytTR07l8ws/T1xUnNomIiIe\n6e7y+JPASefc31ue/44OkveqVauoXV/L1m1biZsaR+LC5uSdnpDOUyueApor89qmWpxzmJl3IxAR\n8YHc3Fxyc3M9254557pewWw98Cnn3EEzWwXEO+fua7fcOeeIfiia66dez9nqs3z/uu+zZMKSd20r\n6sEoav9vLdGR0Z4NQETEj8wM51yfK9me3JjqbuDXZhYDHAY+0dFKrROW7Xve54uPjqe2SclbRKS/\nuk3ezrmdwGVdrRN0QRzuXT3v88VHxVPbWEtybHLfohUREcCjKywDwQBAt5W3Ji1FRLzhSfJuCjYB\ndFt5J8YkUtlQ6cUuRUSGNW8qb9dcedc21jZfpNNJ5T0pdRJHzx31YpciIsOap5V3WV0ZMZExREZE\ndrje9LTpHCw56MUuRUSGNU973ufqznXaMgGYlj6NvNI8L3YpIjKseVZ5x0XFEXTBTlsmANPSlLxF\nRLzgWc87KSYJoMvKe3r6dPJKlLxFRPrLs8o7Pioew7qsvLNTsimqLqKmscaL3YqIDFueJe+oiCji\nouK6rLwjIyKZPHIyh0sPe7FbEZFhy7MJy8iISOKj47usvAGuu+A6vvHGN9omOUVEpPcGtfIG+Pb7\nvk1JbQmrt6/2YtciIsOSZxOWkRbZnLy7qbxjImP4zKWf4c+H/uzFrkVEhiXvK+9ukjfANVOu4Y2j\nb9AYaPRi9yIiw45nPe+etk0AMhMzmTxyMlsKtnixexGRYcezyjsyomdtk1ZXT7qadfnrvNi9iMiw\n41nPuzeVN8C45HGcrT7rxe5FRIYd7yrvHk5YtkqJTaGsvsyL3YuIDDuDfqpgq5S4FMrryr3YvYjI\nsNOT77DsVutFOisXrmRq2tQevSclNoXyeiVvEZG+8CR5t1beV026qsfvUeUtItJ3nl6k0xuqvEVE\n+s7TnndvqPIWEek7T29M1RupcamU15fjnPMiBBGRYSVklXdcVBzQ/I3zIiLSO55epNNb6nuLiPSN\npxfp9Jb63iIifePpjal6S5W3iEjfqPIWEfGhkE1YgipvEZG+6lHGNbNjQAUQABqdcwvbLw+43p8q\nCKq8RUT6qqflsgNynHOlHS1U5S0iMrh60zaxzhYEgr2/PB6aL9Qpq9NtYUVEequnydsBr5nZVjO7\n6/yF/aq81TYREem1nmbcpc6502aWAbxqZvudc2+2LnzlqVdoCDSwasMqcnJyyMnJ6dFGU+NSOVd3\nrvdRi4j4TG5uLrm5uZ5tz3p7bxEzux+ocs59r+W5eyD3AZqCTTy47MFebWtt3lp+sOkHvHLbK716\nn4iI35kZzrlO29Hd6bZtYmYJZjai5XEicC2wu/06fe15jx0xltNVp3v9PhGR4a4nbZMs4A9m1rr+\nr51z7yiVm4JNJEQn9HrnY0aM4XSlkreISG91m7ydc0eB+V2t09cJy1EJo6ior6C+qZ7YqNhev19E\nZLjy7pt0+nCRToRFkJWURWFVoRdhiIgMGyG9PB5gTNIYTlWe8iIMEZFhw7tv0unDhCVo0lJEpC+G\nROWtSUsRkd4Jac8bmitvtU1ERHon9JX3iDFqm4iI9JJ3lXcfe95jkpS8RUR6K+SVt9omIiK9593Z\nJn3seesqSxGR3gt55Z2RkMG5unM0BBq8CEVEZFgI6RcQA0RGRJKZmMmZqjNehCIiMix4NmHZ18ob\ndKGOiEhvhbxtArpEXkSkt0I+YQm6ylJEpLeGROWttomISO+E/CIdaD5dUG0TEZGeU+UtIuJDQ6bn\nrcpbRKTnhkTlPXPUTA6XHqa8rtyLcEREwl7IL9IBSIxJ5D0T38PaQ2u9CEdEJOwNiYt0AJbPWM6L\nB170IhwRkbDnXeXdj543wI3Tb+Qvh/5CY6DRi5BERMKaZxOW/a28x4wYw7T0aazPX8/Rc0dxznkR\nmohIWBoSE5atVsxYwc+2/Yx5P5mn/reISBc8Sd7l9eX9mrBstXzGcn6z9zdER0STeyy3/4GJiIQp\nT5L3h2d/mKykrH5vZ07GHL6w6As8ufxJJW8RkS5Yf3vLZua87k/XNdWR8Z0MCr5UQHJssqfbFhEZ\nCswM55z19f2eVN5ei4uKY9G4RVzyxCVcsfoK1uxeE+qQRESGlB5V3mYWCWwFTjrnbjxvmeeVN0BJ\nTQkFlQXkl+Vz54t3suczezxpzYiIDAX9rbx7mry/BCwARjjnlp+3bECSd3v3vnIv1Q3VPP7Bxwd0\nPyIig2XA2yZmNh64AXgS6POO+uPeJffy3N7nqGqoCsXuRUSGnJ70vH8AfBkIDnAsnRqdNJorsq/g\nd/t+F6oQRESGlC6vrDGzDwJFzrntZpbT2XqrVq1qe5yTk0NOTqer9tkn5n+CH/39R9wx/w7Pty0i\nMtByc3PJzc31bHtd9rzN7JvAbUATEAckA//rnPt4u3UGvOcNUFFfwdjvjaX0vlJiImMGfH8iIgNp\nQHvezrmvO+cmOOcmA7cCf22fuAdTcmwyF6RdwI7CHaHYvYjIkNLb87xDereoJeOXsPHExlCGICIy\nJPQ4eTvn1p1/muBgWzJByVtEBIboFZadWTJhCRtObNDtYkVk2PNV8p4ycgpNwSZOVJwIdSgiIiHl\nq+RtZmqdiIjgs+QNmrQUEQE/Jm9V3iIi/kveC8YuYO/ZvdQ31Yc6FBGRkPFd8o6LimNM0hiOlx8P\ndSgiIiHju+QNMHnkZI6WHQ11GCIiIePP5J06maPnlLxFZPjyb/JW5S0iw5g/k7faJiIyzPkyeU9K\nnaS2iYgMa75M3mqbiMhw58vkPTppNFUNVfpOSxEZtnyZvM2MqWlTOVB8INShiIiEhC+TN8C8rHns\nLtod6jBERELCv8k7cx67zuwKdRgiIiHh3+SdpeQtIsOXr5P3zjM79a06IjIs+TZ5jx0xlqALcqb6\nTKhDEREZdL5N3mam1omIDFu+Td6gSUsRGb78nbxVeYvIMKXkLSLiQ75O3nMy53Cg5ACNgcZQhyIi\nMqh8nbwTohOYmDKR/cX7Qx2KiMig8nXyBpg/ej5/O/m3UIchIjKofJ+8b7/odh7f+rgu1hGRYaXb\n5G1mcWa22cx2mNk+M/vWYATWU9dNvY7axlpeP/p6qEMRERk01pOK1cwSnHM1ZhYFvAXc65x7q2WZ\nC3XV+9KBl7jzxTu5auJVXJh5Iffn3B/SeEREumNmOOesr+/vUdvEOVfT8jAGiARK+7rDgXDjjBvZ\n9MlN3DzzZtbsWcMzu54JdUgiIgOqp5V3BLANuAB43Dn3lXbLQl55t7f55GY+8ruPcOwLx0IdiohI\np/pbeUf1ZCXnXBCYb2YpwP8zsxznXG7r8lWrVrWtm5OTQ05OTl/j6beF4xZS1VBFQUUB45LHhSwO\nEZH2cnNzyc3N9Wx7Paq83/EGs28Atc6577Y8H1KVN8CNa27k9otu50OzPxTqUEREOjTgPW8zG2Vm\nqS2P44H3Adv7usPBsHj8Yv52Qud+i0j46smE5Rjgr2a2A9gMvOScG9Ln5S0ev1gX7ohIWOt12+Rd\nGxiCbZPqhmqyvptF0ZeLSIhOCHU4IiLvMiinCvpNYkwiF42+iI0nNoY6FBGRARGWyRvg6klX89ej\nfw11GCIiAyJ8k/dkJW8RCV9hm7wXT1jM7qLdVDVUhToUERHPhW3yjouKY+aomewp2hPqUEREPBe2\nyRuavyZt95ndoQ5DRMRzYZ28L8y88F3fcfn2qbf55c5fhigiERFvhHXynpc1j91F/6y8gy7Ip//0\naT778mc5U3UmhJGJiPRPWF6k06qouoiZj83k4xd9nOPlxwm4AKcrT7No3CLePP4mE1Im8NJHXwp1\nmCIyDA3KXQX9KjMxk+jIaPad3cddl9xFdWM1yyYtIzEmkef3Ps/XX/86Z6vPkpGYEepQRUR6Jawr\nb4AtBVuYmzm3w8vkr/3Vtdy98G5unHFjCCITkeFMl8d3Y+G4hZ3e32TJhCW6gZWI+FLYJ++uLB6/\nWPc/ERFfGtbJe9H4Rewo3MHS1Ut1/28R8ZVhnbxT41LJuzuPuxfezYrnVrCzcGeoQxIR6ZGwn7Ds\nqYfWPURhVSE/+sCPQh2KiAwDmrD0yO3zb+e5vc9R11QX6lBERLql5N0iOyWbpROWMv3R6axcu5LS\n2tJQhyQi0im1TdppDDRy5NwR/nvDf3Oo9BC5d+QSYRHUNdXxwv4XSI5N5urJVxMXFRfqUEXE5/rb\nNlHy7kAgGGDxU4vJTsmmqLqIo2VHmZE+g6ZgEwdKDvDU8qe4YdoNoQ5TRHxMyXuA7Du7j2d3P8uy\nScvISspibuZcAN46/hYfev5DPPMvz3DNlGtCHKWI+JWSdwj8/h+/51tvfYstn9qCWZ9/9yIyjOls\nkxC4aeZN1DbW8pVXv8KG4xtCHY6IDENK3n0QYRGsXrGapmATtzx/C7/Y8YtQhyQiw4zaJv207+w+\nbnn+FhaNW8TqFavJK8ljevp0tVNEpEvqeQ8BtY21XPvMtURaJOvy1/GzG3/Gpy75VKjDEpEhTD3v\nISA+Op7f/p/fkp2SzWu3vcZXX/sqx8qOhTosEQljqrwHwH2v3kdjsJHvX/f9UIciIkPUgFfeZjbB\nzN4ws71mtsfMVvZ1Z8PF5xZ+jqd3Ps2Rc0fo7D+2msYa8kryCAQDgxydiISDnrRNGoEvOufmAJcD\nnzOzWQMblr9lp2TzqYs/xaU/vZQfbvohR84d4cltT7L55GbufeVe8svymfLIFHKezmHBTxew/fT2\nUIf8Luvz11NcUww0T8quzVsb4ohEpL1et03M7AXgUefc6y3P1TbpxIbjG7jrpbtYMHYB6/PXU1Ff\nweyM2ewt2svKRSt5IOcBntn1DF965UusXr465N+lWd1QzYsHXmRP0R4e2fwIczLn8O1rvs2//eHf\nqGmsYe9n9zI6aXRIYxQJF4N6tomZTQLWAXOcc1Utryl5d8I5x9RHp3K2+iz5X8gnOTaZ+kA9j2x6\nhP9Y8h/ERMYAsPnkZm7+zc08tOwhPnnJJz2NIRAMsC5/HcsmLWv9y8J/vvGfnKg4wcSUiSTFJJGR\nmMHh0sM88fYTXDr2UialTuLeJffyw00/5G8n/8YnL/4kh0sPU1xbzM9X/NzT+ESGq0FL3maWBOQC\n/+Wce6Hd60reXfjexu9RWFXId679TpfrHSo9xNLVS7nrkrs4Xn6cW+feysi4kURYBDNHzSQlLoU3\n899kR+EO/nXev5IWn9b23sKqQr762lc5WXGStPg0slOyibRIpqdPJ+ACfP7Pn+fSsZeSGpdKTWMN\n9YF67rjoDk5XnaayvpLi2mLS49P590v/nenp0zuMr6K+gpmPzeSPt/6Ry8ZdBsCmk5uYP3p+l3dZ\n3F+8n6LqIt44+gZREVGsmLmi7T4x52sINBBpkZTWllJYVciUkVNIjEns7lcs4kuDkrzNLBr4E7DW\nOffD85a5+++/v+15Tk4OOTk5fY0nLDnnenTRzmtHXuPJbU9y2djLePHgizQEGmgMNHKg5ADP/suz\nfOutb2Fm7CzcSXx0PLNGzeJM9RkKKgq4Z9E95EzKobimmOPlxwm4AE/vfJqCigLeuP0N8svziY2M\npaqhihum3UBKXEqvx/GLHb/g/tz7mZc1j0AwwOtHX+e2ebdRXl/O+vz1TEieQEZiBiPjRnLp2Ev5\n44E/cqj0EBNTJrJo3CLMjOf2PEdSTBKXjbuMX970SyIjIgHYeGIjH/7th6lsqMQwxo4YS355Pldm\nX8mztzxLUkxS2ycVL7188GUKqwoJuAAj40Zy1aSrSI5N1m1/xXO5ubnk5ua2PX/ggQcGNnlbc9Z5\nGihxzn2xg+WqvAfYywdf5tN/+jQOR/4X8om0SAoqCzhYcpAxSWPITsnusEItqChgff56PnrhRz2J\nwznHuvx1lNeVU15fzjVTruHKn1/J3My5PPb+xzhVeYqS2hIKKgrYUrCF66dez/IZy4mOjG7bRn1T\nPUfOHWHlX1aSFp9GVmIWe8/uZd/Zffz0gz9l8YTFJEQnkBCdQH1TPV9//es88fYT1AfquWnmTTyY\n8yAzR81kT9EeXj3yKvFR8dx20W1UNVTx6uFXec/E97R9KkmKSaK4ppiNJza+47z7msYadpzZwanK\nUxTXFLNo3CKiIqI4UXGCrae2EhMZwx8+8gfmZMx5x/iTYpJ05ax4ZsArbzO7AlgP7AJaV/6ac+4v\nLcuVvAeYc46lq5dyzZRreHDZg6EO5x3K68pJjEkkKiKqV+8rrinmfzb/D2nxaUxOncx1U6/rsNp1\nznGq8hQjYkfwxNYneHjDwwRdkOTYZD4w7QMUVhXyct7LxETGcNXEq9hSsIXaplqcczQFm4iNiuXy\n8ZczI30GRvO/k5jIGC4afRGpcam8d/J7iY+Of8c+X9j/Ane9dNc7vhIv6IKMThrNN6/+Jh+Z+5E+\n/KZE3kmXxw8TlfWVxEfH9zpJhpvaxlqqG6tJi08jwprPdA0EAzQGG9+V/Gsba4mJjGlrzfSHc45N\nJzdxy/O3sDR7KUkxSTz83ofJSMwAmm9WdrDkINkp2Wq5SI8oeYsMogPFB3jz+JvkleTxg00/oCnY\nRIRFMHnkZE6Un+CW2bfwzM3PdNpeqW6oJjIiUglelLxFQq0h0MC+s/uYlDqJq5++mmnp01gxY0Xb\nJ4P4qHjmZc0jvzyfD//2w5TXl5MSm8KczDm8d/J7+diFH2PKyCk92ldTsInvbvwuG05soKqhit1n\ndlNWV8ayycu4b+l9rM9fzyObH2Fy6mTumH8HE5IncOOMGwdkslf6R8lbZAgpryvnibefYNvpbW2v\nVdRXsOvMLiIsgp988CdcP/V6zlSdYeeZnfw578+s2bOGORlz2iadDSMzMZOE6AQAxiSNYWn2UuZm\nzuWbb36Tbae3cc+iexgRO4LZGbNJj0/nqe1P8evdvyY5Npkf3/BjjpUd41e7fkVeaR51TXU8d8tz\nXJB2QUh+J9IxJW8Rn6tqqOKt42+13ecm4AIUVRdR11SHc4788nw2ntjI/uL9TEqdxGsff+0d5/l3\nxTnHY1se46H1D7FkwhIuGXMJH7vwY0xMmfiOs4Bk8Cl5i0i39hfvZ2/RXtYeWsurR16lMdDIykUr\niYqIYnPBZnYU7uDO+XdS21RLWnxa2zUE45PHM2XkFCamTKSivoKH33qYuZlzWTB2AZtPbqa2qZYV\nM1YwZsQYgi7Y1ioKpdZ8NNRP61TyFpFe+3vB3/nFjl8QFRHFpWMvZVr6NB5+62HGJ4+nuKaYwqpC\nxieP52TFSQ6WHKSuqa75a/9m38LJipMcLz/O7IzZJEQnsDZvLQEXoLaxlvmj53PZ2MuoD9QzMWUi\nsVGxHC8/TlldGQDRkdGkx6dTWFVIQWUBDYEG0uPTaQw2UlFfATSfJVRUXURURBSzMmaRX5bP3My5\nzEifQXJsMtGR0QSCARaMXcDElIk0BBq477X72F20mwnJEzhWdozKhkouHn0x09KmsXjCYq7MvpLJ\nIyeH8lf+LkreIjKgnHOcrTmLYW2nRrYXdEHK6sqIi4pj66mtbD21lYToBI6cO0LQBclOyWZk3EjM\njPqmekpqS8hKzGJ88nhio2IprikmOiKalLgUDCMmMoaspCwaAg3sKdpDdko2205v41TlKcrrymkM\nNuKcY3vh9rb/GL7xnm+wfMZyjpUdY8yIMaTHp7O7aDcHig+w8eRG1h1bR0ZiBpmJmVwx4Qqmpk0F\nICspi5FxIzlWdozMxEwiIyJpCDSw+8xuoiKiKKgsINIi+cD0D3D5+Ms9/b0qeYuIdCMQDPD26bcp\nrS3l9SOvU1hdCMCJ8hOU1pZyQdoFlNSUEHRBIiMimT1qdtuFWQEXYM2eNURHRJORmMGpylMUVRcx\na9QsRsaPBCA1LpUFYxZwZfaVnKw4yYYTG0iPTyfoguwq2kV1QzVfvPyLXDf1uraYlLxFRAZYIBhg\nT9EeztWdY9yIcaQnpLPv7D6qG6pxOEprS1l3bB3bC7eTnpBOzsSctjbQ3My5OBz3/OUe7px/J/WB\nepqCTfzoAz9S8hYRGeq2n97OSwdfIjYyltqmWh5YNsA3pup2A0reIiK9pm+PFxEZhpS8RUR8SMlb\nRMSHlLxFRHxIyVtExIeUvEVEfEjJW0TEh5S8RUR8SMlbRMSHlLxFRHxIyVtExIeUvEVEfEjJW0TE\nh5S8RUR8SMlbRMSHlLxFRHxIyVtExIe6Td5mttrMzpjZ7sEISEREuteTyvvnwPUDHchQlZubG+oQ\nBpTG52/hPL5wHpsXuk3ezrk3gXODEMuQFO5/gTQ+fwvn8YXz2LygnreIiA8peYuI+JA557pfyWwS\n8JJz7sIOlnW/AREReRfnnPX1vVGh3LmIiPRNT04VXANsBKab2Qkz+8TAhyUiIl3pUdtERESGln5N\nWJrZ9Wa238zyzOw+r4IKJTM7Zma7zGy7mW1peS3NzF41s4Nm9oqZpYY6zp7o6AKrrsZiZl9rOZb7\nzeza0ETdc52Mb5WZnWw5ftvN7P3tlvltfBPM7A0z22tme8xsZcvrYXEMuxif74+hmcWZ2WYz22Fm\n+8zsWy2ve3fsnHN9+gEigUPAJCAa2AHM6uv2hsoPcBRIO++1bwNfaXl8H/BwqOPs4ViuBC4Gdnc3\nFmB2yzGMbjmmh4CIUI+hD+O7H/hSB+v6cXyjgfktj5OAA8CscDmGXYwvLI4hkNDyZxSwCbjCy2PX\nn8p7IXDIOXfMOdcIPAes6Mf2hpLzJ2GXA0+3PH4auGlww+kb1/EFVp2NZQWwxjnX6Jw7RvNfnoWD\nEWdfdTI+ePfxA3+Or9A5t6PlcRXwD2AcYXIMuxgfhMExdM7VtDyMobnYPYeHx64/yXsccKLd85P8\n8xfvZw54zcy2mtldLa9lOefOtDw+A2SFJjRPdDaWsTQfw1Z+Pp53m9lOM3uq3cdSX4+v5XTdi4HN\nhOExbDe+TS0v+f4YmlmEme2g+Ri94Zzbi4fHrj/JO1xnOpc65y4G3g98zsyubL/QNX/GCYux92As\nfhzn48BkYD5wGvheF+v6YnxmlgT8L3CPc66y/bJwOIYt4/sdzeOrIkyOoXMu6JybD4wH3mNmy85b\n3q9j15/kXQBMaPd8Au/8n8OXnHOnW/48C/yB5o8uZ8xsNICZjQGKQhdhv3U2lvOP5/iW13zFOVfk\nWgBP8s+Pnr4cn5lF05y4f+Wce6Hl5bA5hu3G90zr+MLtGDrnyoGXgQV4eOz6k7y3AtPMbJKZxQAf\nAV7sx/ZCzswSzGxEy+NE4FpgN83jur1ltduBFzregi90NpYXgVvNLMbMJgPTgC0hiK9fWv5BtLqZ\n5uMHPhyfmRnwFLDPOffDdovC4hh2Nr5wOIZmNqq13WNm8cD7gO14eez6OZv6fppniA8BXwv17G5/\nf2j+qLaj5WdP65iANOA14CDwCpAa6lh7OJ41wCmggeb5iU90NRbg6y3Hcj9wXajj78P47gR+CewC\ndrb8w8jy8fiuAIItfx+3t/xcHy7HsJPxvT8cjiFwIbCtZWy7gC+3vO7ZsdNFOiIiPqS7CoqI+JCS\nt4iIDyl5i4j4kJK3iIgPKXmLiPiQkreIiA8peYuI+JCSt4iID/1/gZQN/GGXdywAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6516e1d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "loss = []\n",
    "\n",
    "for b, e in zip(grad_clf.weigths, grad_clf.estimators):\n",
    "    s += b * e.predict(spam_X_test)\n",
    "    #p = sigmoid(s)\n",
    "    p = np.sign(s)\n",
    "    loss.append(log_loss((spam_y_test+1)/2., (p+1)/2.))\n",
    "    \n",
    "    #loss.append(log_loss((spam_y_test+1)/2., p))\n",
    "    #loss.append(log_loss((spam_y_test+1)/2., (s+1)/2.))\n",
    "    \n",
    "    #loss.append(np.mean(spam_y_test != p))\n",
    "    #loss.append(mean_squared_error(spam_y_test, p))\n",
    "   \n",
    "plt.figure()\n",
    "plt.plot(loss, label='my', color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = 0\n",
    "\n",
    "loss = []\n",
    "f1 = []\n",
    "\n",
    "for b, e in zip(grad_clf.weigths, grad_clf.estimators):\n",
    "    s += b * e.predict(spam_X_test)\n",
    "    #p = sigmoid(s)\n",
    "    p = np.sign(s)\n",
    "    loss.append(log_loss((spam_y_test+1)/2., (p+1)/2.))\n",
    "    f1.append(f1_score(spam_y_test, p))\n",
    "\n",
    "grad_tree = GradientBoostingClassifier(max_depth=3, n_estimators=grad_clf.n_estimators, learning_rate=0.01, random_state=1)\n",
    "grad_tree.fit(spam_X_train, spam_y_train)\n",
    "\n",
    "stage_pred = grad_tree.staged_predict(spam_X_test)\n",
    "sk_loss = map(lambda p: log_loss( (spam_y_test+1)/2., (p+1)/2. ), stage_pred)\n",
    "\n",
    "stage_pred = grad_tree.staged_predict(spam_X_test) # Generator\n",
    "sk_f1 = map(lambda p: f1_score(spam_y_test, p), stage_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEKCAYAAADdBdT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6516c73590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss, label='my', color='g')\n",
    " \n",
    "plt.plot(sk_loss, label='sklearn', color='r')\n",
    "plt.plot(np.array(sk_loss) * 1.03, label='+3%', color='r', alpha=0.5)\n",
    "plt.plot(np.array(sk_loss) * 0.97, label='-3%', color='r', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Log loss vs n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEKCAYAAAD6q1UVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65167d13d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(f1, label='my', color='g')\n",
    "\n",
    "plt.plot(sk_f1, label='sklearn', color='r')\n",
    "plt.plot(np.array(sk_f1) * 1.03, label='+3%', color='r', alpha=0.5)\n",
    "plt.plot(np.array(sk_f1) * 0.97, label='-3%', color='r', alpha=0.5)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"F1 score vs n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vote_clf = VotingClassifier([forest_clf, grad_clf], [1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94739459029435158"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.score(spam_X_test, spam_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.947394590294\n",
      "precision =  0.908004192074\n",
      "recall =  0.936551174596\n",
      "f1 =  0.921265742063\n",
      "Log loss =  1.81693968239\n"
     ]
    }
   ],
   "source": [
    "vote_pred = vote_clf.predict(spam_X_test)\n",
    "p, r, f, _ = precision_recall_fscore_support((spam_y_test+1)/2., (vote_pred+1)/2.)\n",
    "\n",
    "print \"score: \", vote_clf.score(spam_X_test, spam_y_test)\n",
    "\n",
    "print \"precision = \", p.mean()\n",
    "print \"recall = \", r.mean()\n",
    "print \"f1 = \", f.mean()\n",
    "\n",
    "print \"Log loss = \", log_loss((spam_y_test+1)/2., (vote_pred+1)/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting f1 score: 0.969948447127; weigths: (0.0, 0.204081632653)\n",
      "0.885640413683\n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "best_f1 = None\n",
    "best_w1 = None\n",
    "best_w2 = None\n",
    "\n",
    "f_pred = forest_clf.predict(spam_X_test)\n",
    "g_pred = np.sign(grad_clf.predict(spam_X_test))\n",
    "\n",
    "for w1 in np.linspace(0.0, 10.0, num=50):\n",
    "    for w2 in np.linspace(0.0, 10.0, num=50):\n",
    "        if w1 + w2 == 0.0:\n",
    "            continue\n",
    "        voting_clf = VotingClassifier([forest_clf, grad_clf], [w1, w2])\n",
    "        #voting_pred = voting_clf.predict(spam_X_test)\n",
    "        voting_pred = (w1 * f_pred + w2 * g_pred) / (w1 + w2)\n",
    "        voting_pred = np.sign(voting_pred)\n",
    "                \n",
    "        voting_f1 = f1_score(np.array((spam_y_test+1)/2, dtype=int), \n",
    "                             np.array((voting_pred+1)/2, dtype=int))\n",
    "        \n",
    "#         print \"Weigths: {} {}, F1: {}\".format(w1, w2, voting_f1)\n",
    "        \n",
    "        if best_f1 is None or best_f1 < voting_f1:\n",
    "            best_pred = voting_pred\n",
    "            best_f1 = voting_f1\n",
    "            best_w1 = w1\n",
    "            best_w2 = w2\n",
    "            \n",
    "print \"Resulting f1 score: {}; weigths: ({}, {})\".format(best_f1, best_w1, best_w2)\n",
    "print np.mean(voting_pred == best_pred)\n",
    "print best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969948447127\n",
      "0.969948447127\n"
     ]
    }
   ],
   "source": [
    "print f1_score(np.array(spam_y_test, dtype=int), np.array(g_pred, dtype=int))\n",
    "print f1_score(np.array((spam_y_test+1)/2, dtype=int), np.array((g_pred+1)/2, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
