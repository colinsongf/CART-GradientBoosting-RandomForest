{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, depth, max_depth, impurity, is_leaf=False):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity = impurity\n",
    "        \n",
    "    def stopping_criteria(self, X, y):\n",
    "        if self.impurity == 'gini':\n",
    "            return self.depth >= self.max_depth or np.unique(y).shape[0] == 1\n",
    "        else:\n",
    "            return self.depth >= self.max_depth\n",
    "    \n",
    "    def compute_gini_impurity(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        prob = np.array(Counter(y).values()) / float(n)\n",
    "        \n",
    "        impurity = 1. - np.sum(prob**2)        \n",
    "        return impurity\n",
    "    \n",
    "    def compute_mse_impurity(self, X, y):\n",
    "        n = y.shape[0]\n",
    "        impurity = np.var(y) * n\n",
    "        return impurity\n",
    "    \n",
    "    def compute_impurity(self, X, y):\n",
    "        if self.impurity == 'gini':\n",
    "            impurity = self.compute_gini_impurity(X, y)\n",
    "        else:\n",
    "            impurity = self.compute_mse_impurity(X, y)\n",
    "        return impurity\n",
    "    \n",
    "    def compute_impurity_change(self, feature, threshold, X, y):\n",
    "        \n",
    "        pred_X     = X[:, feature] <= threshold\n",
    "        not_pred_X = X[:, feature] >  threshold\n",
    "        \n",
    "        X_left , y_left  = X[pred_X]    , y[pred_X]\n",
    "        X_right, y_right = X[not_pred_X], y[not_pred_X]\n",
    "                \n",
    "        n, l, r = X.shape[0], X_left.shape[0], X_right.shape[0]\n",
    "        \n",
    "        change = float(l) / n * self.compute_impurity(X_left, y_left) + float(r) / n * self.compute_impurity(X_right, y_right)\n",
    "        return change\n",
    "    \n",
    "    def get_predicate(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        best_pair = None\n",
    "        best_impurity = None\n",
    "        \n",
    "        for i in np.arange(m):\n",
    "            \n",
    "            thresholds = np.sort(np.unique(X[:, i]))\n",
    "            for k in xrange(len(thresholds) - 1):\n",
    "                thresholds[k] += thresholds[k + 1]\n",
    "            thresholds = thresholds[:-1] / 2\n",
    "            \n",
    "            for t in thresholds:\n",
    "                new_impurity = self.compute_impurity_change(i, t, X, y)\n",
    "                if best_pair is None or new_impurity < best_impurity:\n",
    "                    best_pair = (i, t)\n",
    "                    best_impurity = new_impurity\n",
    "        \n",
    "        return best_pair\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.stopping_criteria(X, y):\n",
    "            self.is_leaf = True\n",
    "            if self.impurity == 'gini':\n",
    "                self.c = Counter(y).most_common()[0][0]\n",
    "            else:                \n",
    "                self.average = np.mean(y)\n",
    "        else:\n",
    "            predicate = self.get_predicate(X, y)\n",
    "            \n",
    "            if predicate is None:\n",
    "                self.is_leaf = True\n",
    "                if self.impurity == 'gini':\n",
    "                    self.c = Counter(y).most_common()[0][0]\n",
    "                else:\n",
    "                    self.average = np.mean(y)\n",
    "                return\n",
    "            \n",
    "            self.feature, self.threshold = predicate\n",
    "        \n",
    "            pred_X     = X[:, self.feature] <= self.threshold\n",
    "            not_pred_X = X[:, self.feature] >  self.threshold\n",
    "        \n",
    "            self.left = Node(self.depth + 1, max_depth=self.max_depth, impurity=self.impurity)\n",
    "            self.left.fit(X[pred_X], y[pred_X])\n",
    "            \n",
    "            self.right = Node(self.depth + 1, max_depth=self.max_depth, impurity=self.impurity)\n",
    "            self.right.fit(X[not_pred_X], y[not_pred_X])    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.is_leaf:\n",
    "            if self.impurity == 'gini':\n",
    "                return [self.c for _ in X]\n",
    "            else:            \n",
    "                return [self.average for _ in X]\n",
    "        else:\n",
    "            pred = []\n",
    "            for x in X:      \n",
    "                if x[self.feature] <= self.threshold:\n",
    "                    pred.extend(self.left.predict(np.array([x])))\n",
    "                else:\n",
    "                    pred.extend(self.right.predict(np.array([x])))\n",
    "            return pred\n",
    "        \n",
    "class CART:\n",
    "    def __init__(self, impurity='gini', max_depth=5):\n",
    "        if impurity not in ['gini', 'mse']:\n",
    "            raise ValueError(\"Only gini and mse criteria are supported\")\n",
    "        self.impurity = impurity\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = Node(1, max_depth=self.max_depth, impurity=self.impurity)\n",
    "        self.root.fit(X, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array(self.root.predict(X))\n",
    "    \n",
    "    def score(self, X, y):        \n",
    "        #y_pred = sigmoid(self.predict(X))\n",
    "        y_pred = self.predict(X)\n",
    "        #return log_loss(y, y_pred)\n",
    "        return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td> 7.0</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 4.7</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td> 6.4</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 4.5</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td> 6.9</td>\n",
       "      <td> 3.1</td>\n",
       "      <td> 4.9</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td> 5.5</td>\n",
       "      <td> 2.3</td>\n",
       "      <td> 4.0</td>\n",
       "      <td> 1.3</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td> 6.5</td>\n",
       "      <td> 2.8</td>\n",
       "      <td> 4.6</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width            class\n",
       "50           7.0          3.2           4.7          1.4  Iris-versicolor\n",
       "51           6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "52           6.9          3.1           4.9          1.5  Iris-versicolor\n",
       "53           5.5          2.3           4.0          1.3  Iris-versicolor\n",
       "54           6.5          2.8           4.6          1.5  Iris-versicolor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.data', delimiter=',')[50:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 0\n",
    "}\n",
    "\n",
    "df[\"num_class\"] = df[\"class\"].apply(lambda s: classes[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "      <td> 100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>   6.262000</td>\n",
       "      <td>   2.872000</td>\n",
       "      <td>   4.906000</td>\n",
       "      <td>   1.676000</td>\n",
       "      <td>   0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>   0.662834</td>\n",
       "      <td>   0.332751</td>\n",
       "      <td>   0.825578</td>\n",
       "      <td>   0.424769</td>\n",
       "      <td>   0.502519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>   4.900000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>   5.800000</td>\n",
       "      <td>   2.700000</td>\n",
       "      <td>   4.375000</td>\n",
       "      <td>   1.300000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>   6.300000</td>\n",
       "      <td>   2.900000</td>\n",
       "      <td>   4.900000</td>\n",
       "      <td>   1.600000</td>\n",
       "      <td>   0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>   6.700000</td>\n",
       "      <td>   3.025000</td>\n",
       "      <td>   5.525000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>   7.900000</td>\n",
       "      <td>   3.800000</td>\n",
       "      <td>   6.900000</td>\n",
       "      <td>   2.500000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width   num_class\n",
       "count    100.000000   100.000000    100.000000   100.000000  100.000000\n",
       "mean       6.262000     2.872000      4.906000     1.676000    0.500000\n",
       "std        0.662834     0.332751      0.825578     0.424769    0.502519\n",
       "min        4.900000     2.000000      3.000000     1.000000    0.000000\n",
       "25%        5.800000     2.700000      4.375000     1.300000    0.000000\n",
       "50%        6.300000     2.900000      4.900000     1.600000    0.500000\n",
       "75%        6.700000     3.025000      5.525000     2.000000    1.000000\n",
       "max        7.900000     3.800000      6.900000     2.500000    1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(df, train_percent=0.8):\n",
    "    X = np.copy(df.values)\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    X, y = X[:, :-1], X[:, -1]\n",
    "    \n",
    "    train_size = int(X.shape[0] * train_percent)\n",
    "    \n",
    "    X_train, y_train = X[:train_size, :], y[:train_size]\n",
    "    X_test, y_test = X[train_size:, :], y[train_size:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60; Test size: 40;\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle(df.drop(\"class\", axis=1), train_percent=0.6)\n",
    "print \"Train size: {}; Test size: {};\".format(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CART instance at 0x7f9313d33bd8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_clf = CART(max_depth=10)\n",
    "cart_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = cart_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.59044820949\n",
      "Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "print \"Log loss: {}\".format(log_loss(y_test, pred))\n",
    "print \"Accuracy: {}\".format(cart_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.59044820949\n",
      "Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "#print \"Log loss: {}\".format(log_loss(y_test, sigmoid(pr)))\n",
    "print \"Log loss: {}\".format(log_loss(y_test, pr))\n",
    "print \"Accuracy: {}\".format(tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=10, poi=1.0, pof=1.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.poi = poi\n",
    "        self.pof = pof\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.estimators = []\n",
    "        for _ in xrange(self.n_estimators):\n",
    "            n, m = X.shape\n",
    "            items    = np.sort(np.random.choice(n, n * self.poi))\n",
    "            features = np.sort(np.random.choice(m, m * self.pof, replace=False))\n",
    "                            \n",
    "            estimator = CART(max_depth=self.max_depth)\n",
    "            estimator.fit(X[:, features][items, :], y[items])\n",
    "            \n",
    "            self.estimators.append(estimator)            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        for e in self.estimators:\n",
    "            p = e.predict(X)\n",
    "            p[p == 0] = -1\n",
    "            answer += p\n",
    "        answer /= self.n_estimators\n",
    "        answer = np.sign(answer)        \n",
    "        answer[answer == -1] = 0\n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)        \n",
    "        return np.mean(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:13: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForest(n_estimators=100, max_depth=10)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, mu=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth        \n",
    "        self.mu = mu\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.estimators = []\n",
    "        self.weigths = []\n",
    "        \n",
    "        estimator = CART(max_depth=self.max_depth, impurity='gini')\n",
    "        estimator.fit(X, y)\n",
    "        \n",
    "        h = estimator.predict(X)\n",
    "        for _ in xrange(self.n_estimators):            \n",
    "            g = y - sigmoid(h)\n",
    "            \n",
    "            estimator = CART(max_depth=self.max_depth, impurity='mse')\n",
    "            estimator.fit(X, g)\n",
    "            \n",
    "            self.estimators.append(estimator)\n",
    "            \n",
    "            #p = estimator.predict(X)            \n",
    "            #func = lambda b: log_loss(y, h + b * p)\n",
    "            #b = scipy.optimize.minimize(func, np.zeros((y.shape[0],))).x\n",
    "            #print b\n",
    "            #b = 1            \n",
    "            b = self.mu\n",
    "            \n",
    "            self.weigths.append(b)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        for (b, a) in zip(self.weigths, self.estimators):            \n",
    "            answer += b * a.predict(X)\n",
    "        answer /= self.n_estimators\n",
    "        answer = np.sign(answer)\n",
    "        answer[answer == -1] = 0\n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad_clf = GradientBoosting(n_estimators=100)\n",
    "grad_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grad = GradientBoostingClassifier(n_estimators=100, max_depth=5)\n",
    "grad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VotingClassifier:\n",
    "    def __init__(self, estimators, weigths):\n",
    "        self.estimators = estimators\n",
    "        self.weights = weigths\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        answer = 0\n",
    "        for weight, estimator in zip(self.weights, self.estimators):\n",
    "            p = estimator.predict(X)\n",
    "            p[p == 0] = -1\n",
    "            answer += weight * p\n",
    "        answer = np.sign(answer / len(self.estimators))\n",
    "        answer[answer == -1] = 0\n",
    "        return answer\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:13: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "vote_clf = VotingClassifier([forest_clf, grad_clf], [1.0, 1.0])\n",
    "vote_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
